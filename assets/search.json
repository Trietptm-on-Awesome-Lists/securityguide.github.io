[{
  "title": "Abusing Cookies",
  "url": "/webappsec/fundamentals/abusing-cookies.html",
  "tags": "",
  "content": "How cookies work  If you have ever done any web programming, you are familiar with cookies. However, you might not be familiar with some of the unexpected ways in which cookies can create security vulnerabilities.  A look at cookies  Let us start at the beginning: what is a cookie? The HTTP cookie allows a server to store a bit of arbitrary data on the client’s device. A cookie is just a KEY=VALUE pair, with some associated attributes the direct the browser when the cookie should be used.  Cookies are just headers set by the server in the HTTP response or by the client in the HTTP request. For example:  1. client -&gt; server request  curl --head -v https://en.wikipedia.org/wiki/Main_Page 2&gt;&amp;1 | grep '^&gt;'    SIDE NOTE: the `grep '^&gt;'` command will show us just the client's request headers  &gt; HEAD /wiki/Main_Page HTTP/1.1 &gt; Host: en.wikipedia.org &gt; User-Agent: curl/7.47.0 &gt; Accept: */*   2. client &lt;- server response  curl --head -v --cookie-jar /tmp/cookie https://en.wikipedia.org/wiki/Main_Page 2&gt;&amp;1 | grep '^&lt;'    SIDE NOTE:     * the `--cookie-jar` argument will save the cookies to the file specified     * the `grep '^&lt;'` command will show us just the server's response headers  Server responds with two Set-Cookie headers:  &lt; Set-Cookie: WMF-Last-Access=04-Nov-2016;Path=/;HttpOnly;secure;Expires=Tue, 06 Dec 2016 12:00:00 GMT &lt; Set-Cookie: GeoIP=US:::37.75:-97.82:v4; Path=/; secure; Domain=.wikipedia.org   3. client -&gt; server request  curl --head -v --cookie /tmp/cookie https://en.wikipedia.org/wiki/Main_Page 2&gt;&amp;1 | grep '^&gt;'  When the client next mades a request, it will send these cookies in the request header:  &gt; HEAD /wiki/Main_Page HTTP/1.1 &gt; Host: en.wikipedia.org &gt; User-Agent: curl/7.47.0 &gt; Accept: */* &gt; Cookie: WMF-Last-Access=31-Oct-2016; GeoIP=US:::37.75:-97.82:v4   Domains and Paths          If the domain is not explicitly set by the server, the browser will assign the domain based on the origin of the cookie.           Sub-domains can set cookies for the parent domain: A page can set a cookie for its own domain or any parent domain, as long as the parent domain is not a public suffix. In other words, sub.domain.org can set a cookie for domain.org, which will also be used for sub2.domain.org. Firefox and Chrome use the Public Suffix List to determine if a domain is a public suffix.           A cookie for a parent domain is always sent to the sub-domain: a cookie with domain=domain.org or domain=.domain.org will be sent to sub.domain.org. Because of this, a compromise on domain.org can result in session fixation vulnerability for all the subdomains.           Cookie scheme for determining origin is very different than the same-origin policy. The short hand version: cookie domain is a loose match, same-origin is a very strict match, including protocol and port.      Cookie Flags  A cookie flag is a suggestion to the client regarding when a cookie should be used.  Example:  Set-Cookie: KEY=VALUE; Secure; HttpOnly; SameSite=Strict   Secure  The secure flag suggests to the client that they cookie should only be used for requests over https.  Why this is highly recommended:     Suppose your browser has an active session to https://securebank.int, then you type in ‘securebank.int’ in another tab. Without the Secure flag, your browser has just leaked your session id in the clear over the network! This is true even if you don’t serve any content on plaintext http and always redirect to https.   HttpOnly  This flags prevents javascript from reading the value of the cookie.  Why this is highly recommended:     This flag makes it harder for XSS attacks to hijack your session by reading the cookie and exfiltrating the session id to the attacker’s domain.   SameSite=Strict  This flag prevents the cookie from being used by other web pages when they submit forms or get resources from the cookie’s domain.  Why this is highly recommended:     SameSite restrictions are a good way to mitigate CSRF attacks.   Cookie facts     Cookie size: Cookies can hold no more than 4096 bytes.   Duplicate Cookies: It is possible to have multiple cookies with the same name for the same domain. The server must not rely on any particular order of the cookies.   Abusing Cookies  Session fixation  By resetting the session before setting critical information in the session, you protect against session fixation attacks.  Why this is important: There are many ways that an attacker can “pre-seed” a session cookie in the target’s browser. Once this is done, browsers follow a simple rule with cookies: if they have a cookie that matches the site, they send the cookie. Because of this, the website has no way to distinguish between legitimate session cookies that are created by the target and nefarious session cookies created by the attacker (and injected into the target’s browser).  Remember:     Encrypted and signed session cookies offer no defense against session fixation.   If you are using a third party authentication framework, you most likely still need to worry about resetting the session yourself. This includes SAML authentication libraries.   Session hijacking  To be written.  There are various ways that a session ID can leak. Then an attacker can assume your session.  Cross site request forgery  When a web browser submits a HTTP request, it dutifully includes all matching cookies, regardless of what web page the request came from. Without protection from Cross Site Request Forgery (CSRF), a web page on a completely different site can get your browser to make requests to a protected site while authenticated as you.  Remember:     Idempotent HTTP GET: You must remember to make all GET actions idempotent (does not change the data). This is because most schemes for anti-CSRF only applies to HTTP POST.   Images are not protected: Images and other assets are not protected by most anti-CSRF or the same-origin policy. If you have images with sensitive information, then you need an additional system to prevent a third party site from stealing these images.   If the application has a XSS vulnerability, then CSRF is also defeated.   Parsing cookies  To be written.  Cookies are untrusted input. If there is a bug in the parsing code, such as a JSON or XML library, then an attacker can exploit it via cookies"
},{
  "title": "Abusing Filesystems",
  "url": "/webappsec/fundamentals/abusing-filesystems.html",
  "tags": "",
  "content": "temp files   relative paths   path injection   predictable paths   file uploads"
},{
  "title": "Abusing Input",
  "url": "/webappsec/fundamentals/abusing-input.html",
  "tags": "",
  "content": "SQL Injection  “SQL Injection” is a security vulnerability with a very simple cause: it occurs whenever user input is not properly filtered when SQL queries are built.  It is one of the most common vulnerabilities, can lead to total compromise of the database, and is also easy to prevent.  To prevent SQL Injection:     Always use parameter binding. Almost all libraries for accessing a database include some API for “parameter binding”. You should always use these built-in methods.   Avoid every trying to filter input yourself. Use the parameter binding feature that is already built into the database library you are using.   If you are creating a custom query that must bypass parameter binding, try to exercise extreme caution. For example, only allow a very limited set of characters in the user input.   Examples  A vulnerable query (java):  String query = \"SELECT account_balance FROM user_data WHERE user_name = \" + request.getParameter(\"customerName\"); Statement statement = connection.createStatement(...); ResultSet results = statement.executeQuery(query);   In this vulnerable query, if the parameter customerName contained ''; DROP TABLE user_data; then an attacker could destroy the database (there are other techniques that can be used to exfiltrate data as well).  A safe query using parameter binding (java):  String custname = request.getParameter(\"customerName\"); String query = \"SELECT account_balance FROM user_data WHERE user_name = ? \"; PreparedStatement pstmt = connection.prepareStatement(query); pstmt.setString(1, custname); ResultSet results = pstmt.executeQuery();   Where it gets tricky  Many database APIs will not use parameter binding for all calls, even when it looks like they do. For example, in Ruby using ActiveRecord, this call is unsafe:  User.exist?(params[:id])   If params[:id] is encoded as an array by the attacker, then it will allow an attacker to bypass any input filtering.  A static analysis tool in your test pipeline should help detect these sort of non-obvious errors for you.  Further reading     netspi SQL wiki, An excellent in-depth look at SQL injection.   OWASP page on SQL injection   OWASP SQL Injection Prevention Cheat Sheet"
},{
  "title": "Access Controls",
  "url": "/webappsec/best-practices/access-controls.html",
  "tags": "",
  "content": "Are there tests for failed authentication states?  https://martinfowler.com/articles/web-security-basics.html     Use existing authentication frameworks whenever possible instead of creating one yourself   Support authentication methods that make sense for your needs   Limit the ability of an attacker to take control of an account   You can take steps to prevent attacks to identify or compromise accounts   Never use default or hard-coded credentials   Proper Access Controls  This one is tricky as it is very dependent on the context of your application. Here are some things to consider:     How do users authenticate? Are you using a secure library?   Should only privileged users have access to certain resources? Where are these roles stored? Could they be manipulated by user input?   What systems/services can access your database?   This last point is absolutely critical. App context varies, but an anonymous user/system/service should never be able to access your database. Make sure there is a strong authentication model for your database.  More Resources:     OWASP Authentication Cheat Sheet   MongoDB   AWS Elastic Search   MySQL   PostgreSQL   Microsoft SQL Server"
},{
  "title": "Agnostic dependency check",
  "url": "/webappsec/tools/agnostic-tools/agnostic-dependency-checker.html",
  "tags": "",
  "content": "Hawkeye  Hawkeye (free, cli and SaaS) https://github.com/Stono/hawkeye and https://hawkeye.website"
},{
  "title": "Agnostic dynamic analysis",
  "url": "/webappsec/tools/agnostic-tools/agnostic-dynamic-analysis.html",
  "tags": "",
  "content": "Arachni  Arachni is a web application security scanner framework that works well with Rails, but can also be used with many frameworks."
},{
  "title": "Agnostic secrets management",
  "url": "/webappsec/tools/agnostic-tools/agnostic-secrets-management.html",
  "tags": "",
  "content": "I don’t think you need to be scared into not checking secrets in – you probably already understand that this is bad (maybe). Just in case, here is a handy rule: never commit cleartext secrets of any kind to git, no matter what.  Environment variables  AWS Parameter Store  https://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-paramstore.html  GoCD  go-env https://docs.gocd.org/15.3.0/faq/dev_use_current_revision_in_build.html  Heroku  https://devcenter.heroku.com/articles/config-vars  Encrypted in cloud storage  cred-stash  Store secrets in AWS using encrypted S3 buckets  https://github.com/fugue/credstash  Vault  https://www.vaultproject.io/  Encrypted in source code  git-crypt  With git-crypt, you can store files in git that are automatically encrypted using GnuPG.  Install  $ brew install gnupg git-crypt   Initialize in your repo  $ cd my_project $ git crypt init   Add public keys that can decrypt the files:  $ git-crypt add-gpg-user USER_ID   Specify which files should be encrypted in the .gitattributes file:  *.key filter=git-crypt diff=git-crypt   After cloning a repository with encrypted files, unlock with:  $ git-crypt unlock   Check which files are encrypted:  $ git crypt status   BlackBox  https://github.com/StackExchange/blackbox  Like git-crypt, blackbox helps you store secrets in git using GnuPG. Blackbox will also with any source control, not just git.  With BlackBox, however, nothing is automatic. If you want to edit a file, you must decrypt it first. In contrast, git-crypt is automatic, which can be weird and confusing. The BlackBox approach can be more comforting and safe, because you never commit what appears to be a cleartext file. But the manual approach can also be painfully laborious.  Install  $ brew install blackbox   Initialize in your repo:  $ cd my_project $ blackbox_initialize   Add public keys that can decrypt the files:  $ blackbox_addadmin coworker@thoughtworks.com   Specify what files should be encrypted:  $ blackbox_register_new_file path/to/file.name.key   Unlock, edit, lock, commit:  $ blackbox_edit_start FILENAME ... edit file ... $ blackbox_edit_end FILENAME $ git commit ...   Further reading  https://12factor.net/config"
},{
  "title": "Agnostic static analysis",
  "url": "/webappsec/tools/agnostic-tools/agnostic-static-analysis.html",
  "tags": "",
  "content": "GrepBugs  GrepBugs is a regex-based static analysis tool that looks for potentially dangerous methods and patterns in your code. Given that this is regex, it can be noisy, but the reports provide enough context to quickly weed out false positives.  Another helpufl aspect of GrepBugs is that it gives you quick feedback about the numbers of file types, and even lines of code present.  Installation &amp; Usage  To install GrepBugs, you simply clone the GitHub repository:  $ git clone https://github.com/foospidy/GrepBugs.git   I’d recommend either:     cloning it into your project folder        placing it in your home directory and adding the following line to your .bash_profile:      $ alias grepbugs =’python2 ~/Grepbugs/grepbugs.py’      This will allow you to run a scan anywhere, all you have to do is set the target path:  $ grepbugs -d my/project   Other Notes  When you run a scan, the output will be created in the ‘out/’ folder. By default, two files will be created for every scan: .html and .txt  The default name for the scan will be the path you provided."
},{
  "title": "Backups",
  "url": "/opsec/level-two/backups.html",
  "tags": "",
  "content": "See Also     Security Planner / Windows Backup   Security Planner / Time Machine (MacOS)   Security Planner / Back Up Your iPhone   Security In-a-box / Recover From Information Loss"
},{
  "title": "Better Browsing",
  "url": "/opsec/level-one/better-browsing.html",
  "tags": "",
  "content": "Keep your browser up to date  All four major web browsers, Firefox, Chrome, Microsoft Edge, and Safari, have experienced severe security flaws in the recent past, so you should make sure you are using the most up-to-date version, whichever one you choose.  If you have install the web browser through the offical application store for your operating system, then the store should take care of updates.  Otherwise, the browser will alert you when a new version of the application is available. Do not ignore these alerts! Yes, new applications are not always better or more fun to use, but when it comes to web browers it is vitally important to be running the latest release.  Adjust your settings  Disable third-party cookies  Third-party cookies are tracking identifiers used by advertising networks to track your behavior as you browse from website to website. They are an abomination and serve no legitimate purpose.     Firefox: Preferences &gt; Privacy &gt; Accept third-party cookies &gt; Never.   Chrome: Settings &gt; Show advanced settings… &gt; Content settings &gt; Block third-party cookies and site data.   Clear cookies on exit  Most browsers keep cookies around much longer than necessary. It is best to configure your browser to delete cookies when you quit the browser.     Firefox: Preferences &gt; Privacy &gt; Keep until &gt; I close Firefox.   Chrome: Settings &gt; Show advanced settings… &gt; Content settings &gt; Keep local data only until you quit your browser.   Disable Flash  Flash is a plug-in from Adobe that has been the cause an endless stream of security problems. We highly recommend that you remove or disable Flash.     Firefox: Add-ons &gt; Plugins &gt; Flash &gt; Never Activate.   Chrome: Settings &gt; Show advanced settings… &gt; Content settings &gt; Do not run plugins by default.   Disable Java  Java also has many security problems and you probably have never used it. Remove or disable it with haste.     Firefox: Add-ons &gt; Plugins &gt; Java &gt; Never Activate.   Chrome: Settings &gt; Show advanced settings… &gt; Content settings &gt; Do not run plugins by default.   Change default search engine  While you are adjusting your setting, take the opportunity to change your default search engine to [[duckduckgo.com =&gt; https://duckduckgo.com]]. Unlike Google and Bing, DuckDuckGo does not track your searches in order to sell your behavior to advertisers. The best way to avoid leaking your data to an attacker is to ensure that the data is never stored in the first place. See instructions for [[desktop browsers =&gt; https://duck.co/help/desktop/adding-duckduckgo-to-your-browser]] or [[mobile browsers =&gt; https://duck.co/help/mobile]].  Browser extensions  The extensions in this list work for both Firefox and Chrome, unless otherwise noted.  Essential extensions  These are absolutely essential browser extensions that everyone should be using all the time. They are stable, open source, and rarely cause websites to break.     [[uBlock Origin -&gt; https://github.com/gorhill/uBlock]]   uBlock prevents most advertisements and tracking networks. It is similar to Adblock Plus or Disconnect but works better and is much faster. Install for [[Chrome =&gt; https://chrome.google.com/webstore/detail/ublock-origin/cjpalhdlnbpafiamejdnhcphjbkeiagm]], [[Firefox =&gt; https://addons.mozilla.org/en-US/firefox/addon/ublock-origin/]].   [[HTTPS Everywhere =&gt; https://www.eff.org/https-everywhere]]   HTTPS Everywhere will automatically switch to secure TLS connections whenever the website supports it. This helps to protect against surveillance of the content of your web browsing, although it does not hide which websites you are visiting (unless you also run [[Tor]] or a [[VPN]]).   [[Privacy Badger =&gt; https://www.eff.org/privacybadger]]   Privacy Badger dynamically detects attempts to track your browsing behavior and blocks content from these trackers. Privacy Badger is not designed to stop ads, so it is not a replacement for uBlock, but it includes some security features that uBlock (in default mode) does not have.   Usage notes:     Leaking IP addresses: All browsers will leak your real IP address when using audio or video conferencing. If you use a VPN or Tor with audio or video chat, then you should open the uBlock settings and enable the option that prevents WebRTC from leaking your real IP address.   uBlock advanced mode: If you run uBlock in [[advanced mode =&gt; https://github.com/gorhill/uBlock/wiki/Advanced-user-features]], you should not also run Privacy Badger.   Advanced extensions  These extensions are for advanced users because they are complicated to use or cause many websites to malfunction.  These extensions attempt to overcome basic privacy flaws in how web browsers work. However, many websites rely on these privacy flaws for basic functionality, so attempts to fix these problems can often make a website stop working.  Some of these privacy flaws include:     HTTP Referrer: When you click a link, your browser sends to the new website the location of the old website. Because sensitive or personally identifying information might be included in the URL of a particular page, the HTTP Referrer should be disabled. You can only do this with an extension.   HTTP User-Agent: Your web browser sends a special “User-Agent” string to every website that it visits. This string contains a lot of uncommon information that can be used, in combination with other data, to uniquely identify your traffic. There is little point in this browser fingerprint these days, and it is better to use a generic value, such as the one used by the Tor Browser.   HTML5 Canvas: Many websites have started to use the HTML5 Canvas to uniquely fingerprint your browser and track your behavior. There is currently no way to disable this, although some new extensions make a crude attempt.   JavaScript: JavaScript is essential for most websites these days, but there are times when you may wish to disable it. When JavaScript is enabled, it is much easier for a website to fingerprint your browser and track your behavior. Also, most browser security vulnerabilities are caused by JavaScript.   For Firefox:     [[Self Destructing Cookies (Firefox) =&gt; https://addons.mozilla.org/en-US/firefox/addon/self-destructing-cookies/]] will clean out the cookies for a website when all the tabs for that site have been closed (rather than requiring that you restart the browser).   [[µMatrix =&gt; https://addons.mozilla.org/en-US/firefox/addon/umatrix/]] allows you to selectively block Javascript, plugins or other resources and control third-party resources. It also features extensive privacy features like user-agent masquerading, referering blocking and so on. It effectively replaces NoScript and RequestPolicy.   [[User-Agent Switcher =&gt; https://addons.mozilla.org/en-US/firefox/addon/user-agent-switcher/]] will allow you to modify the HTTP User-Agent.   [[Canvas Fingerprint Blocker =&gt; https://addons.mozilla.org/en-US/firefox/addon/canvasblocker/]] will allow you to disable HTML5 canvas support for particular websites.   For Chrome:     [[µMatrix =&gt; https://chrome.google.com/webstore/detail/%C2%B5matrix/ogfcmafjalglgifnmanfmnieipoejdcf]] allows you to selectively block Javascript, plugins or other resources and control third-party resources. It also features extensive privacy features like user-agent masquerading, referering blocking and so on. It effectively replaces NoScript and RequestPolicy.   [[User-Agent Switcher =&gt; https://chrome.google.com/webstore/detail/user-agent-switcher/ffhkkpnppgnfaobgihpdblnhmmbodake]] will allow you to modify the HTTP User-Agent.   [[CanvasFingerPrintBlock =&gt; https://chrome.google.com/webstore/detail/canvasfingerprintblock/ipmjngkmngdcdpmgmiebdmfbkcecdndc]] will block most HTML5 Canvas fingerprinting (not open source).   See also     Security Education Companion / HTTPS Everywhere and Privacy Badger   Security Planner / HTTPS Everywhere   Security Planner / Check Website Names   Security Planner / Privacy Badger"
},{
  "title": "Cloud Settings",
  "url": "/opsec/level-two/cloud-settings.html",
  "tags": "",
  "content": "G Suite for Organizations  Text from Digital security checklists for US Non-profits by Information Ecology (Creative Commons: Attribute-ShareAlike)  Introduction  Many organizations rely on Google’s free online applications (Gmail, Google Docs/Sheets, GDrive, and Google Calendar among them) to do their work. While many staff access these services through individual Gmail accounts (any username that ends with @gmail.com), or a link between their work email address and an existing individual account, Google also offers G Suite: a version of these tools suited for use in organizations. G Suite provides significant advantages over individual accounts, including organizational email addresses using your chosen domain name (the part of an email address after the @ sign), administrative controls, advanced settings, 24/7 tech support for use of the tools. These features can improve your organization’s technology in many areas, including helping you better secure your information by providing tighter management, control, and monitoring of your systems and how they are used.  For those organizations that have already adopted G Suite, the checklist that follows offers direction on how to set up and use the administrative controls offered by the free G Suite Basic platform to harden your organizational G Suite account and improve your overall digital security level. (In this context, “harden” means to reduce the points of vulnerability of a system by turning off or disabling functionality that is not needed.) Note that, as indicated in the associated descriptions, many of these tasks are specific implementations of checklist items from elsewhere in this set.  Make a plan  Make a plan, preferably before deploying G Suite, detailing how your information is used by your staff, volunteers, and others, to ensure that you understand your security needs and can configure the tools correctly.  G Suite is a powerful platform with a lot of moving parts and a lot of possible configurations. As with all tools, the more time and energy you put into understanding the different users and user types you have and what features they need to use, the more effective your implementation of security controls will be. First read through this checklist to familiarize yourself with some practices you may want to employ in your G Suite setup. Then make a list of all the different groups of people you have in your organization that will be using G Suite; a typical list might be: full-time staff, part-time staff, volunteers, and board members. Then think about and list how each of those groups will need each of the various tools that are part of G Suite: e.g., to send email, to edit documents, to access your shared contacts list, to maintain a shared calendar, and so on. Does any single group need a tool that no one else needs? Conversely, does any group have no need for a tool that everyone else uses? Also think about any shared roles where multiple people need access to the same identity, email box, or set of documents – such as an email account used to send or receive invoices, or a set of documents used for a volunteer-run hotline. Google has produced a lot of documentation on how to plan your G Suite deployment (https://support.google.com/a/answer/4514329); reading through it will help you understand the applications and settings available to you in your configuration process. At a minimum, having a well-crafted plan will guide you as you step through the administrative tools at https://admin.google.com and also help you formulate specific questions for G Suite support as you go through the setup.*  Create an admin account  Create a single, dedicated account with full administrative control of G Suite (“Super Admin” permissions) and do not associate it with with any individual’s email address; provide a recovery email address or phone number that is controlled by your organization or a trusted tech support provider and not an individual employee. Assign other administrative permissions appropriately.  While convenient, giving everyday user accounts permission to administer your G Suite creates risk. Doing so can mean that the loss or theft of a person’s device, or a breach of their password, could put all of your organization’s information at risk. Instead, sign up with or create a unique email address (like GSuite@yourdomain.org, replacing yourdomain.org with your organization’s domain name) for this purpose; do not use it for anything else. Give this account “Super Admin” permissions (which means full control over your G Suite setup, including access to all calendars and accounts), remove those permissions from any other accounts (note that the account you use to perform your G Suite setup will have Super Admin permissions assigned automatically), and store the password in a safe way such as a well-configured password manager (see the Password and Authentication Security checklist for more information) or safety deposit box, using it only when you need to change settings in G Suite. You will be asked to give a recovery email or phone number in case of a lost password. This email or phone should be controlled by your organization or trusted delegate such as a tech support provider or affiliate organization rather than by an individual employee. You can find instructions for giving or taking away Super Admin permissions for a user at https://support.google.com/a/answer/172176. Directions for setting up a recovery phone number or email are at https://support.google.com/accounts/answer/183723.  Other levels of administrative control can be assigned according to your organizational needs. For example, you could give a tech support provider Help Desk Admin permissions, which will allow them to reset passwords for people but not create users or groups. You can give control of that account to someone who does tech support without giving them total control of your systems. You can review the built-in administrative groups and find a link on how to make custom roles of your own at https://support.google.com/a/answer/2405986. Creating new users is the most common administrative task in many organizations and, although it may be tempting to delegate this permission to a normal operating account, gaining the power to create a user and add it to groups effectively gives a malicious actor access to all of your files until the user they create is identified and disabled, so it is best to give this permission only to specialized administrative accounts.  Enforce password length rules  G Suite allows you to set minimum (and maximum) password lengths. Setting a minimum length of at least 12 characters helps guard against easily guessable passwords. Instructions on getting this up are at https://support.google.com/a/answer/139399?hl=en.  Grant the least acceess as required  Use the organizational units functionality in G Suite to make groupings of user accounts or devices, and give them the minimum level of access required to do their work.  Giving all users ability to use all the G Suite tools in any way they want invites security risk for your organization. Instead, you should practice the security concept of “least authority”–meaning you give users only the minimum access that is required for them to do their work. For example, you may want have volunteers enter information into Google Sheets but not send email from accounts with your domain name. To allow you to control access in this way efficiently rather than on a per-user basis, G Suite provides a structure called an organizational unit. Organizational units allow you to categorize users or devices into groups, and then assign policies to each of those groups. These policies cover things like the ability to access specific tools or to apply certain settings to their accounts. You can read an overview of applying policies at https://support.google.com/a/topic/1227584. An article about organizational structures is at https://support.google.com/a/answer/4352075 and instructions for creating units is at https://support.google.com/a/answer/182537.  Once you have created these units, you can use them to control access to services as described at https://support.google.com/a/answer/182442 or to apply specific settings about those services as described at https://support.google.com/a/answer/2655363.  Use Team Drives  Use Google Groups and Team Drive features to provide appropriate access to files for different groups of users, and to ensure that your organization always controls its own information.  Historically, one of the challenges of managing your organization’s files using Google Drive has been the risk of loss of access to key documents when employees or volunteers leave the team, as well as the lack of ability to prevent sensitive information from being shared more widely than it should be. By setting up one or more Team Drives (as described at https://support.google.com/a/answer/7212025), you can ensure that the Super Admin for your G Suite domain always has access to the files that are stored there. You can also apply permissions (as described at https://support.google.com/a/answer/7337635?hl=en) to a Team Drive to allow only the minimum access needed. For example, you might have organizational policy documents that everyone needs to be able to view and only certain staff members should be able to change. You can give these permissions by individual email address if your organization is small enough, and, for larger groups and easier management, you can create Google Groups ((https://support.google.com/a/answer/33329)) and give appropriate permissions to the Group’s email address. This way when a new person comes on board or leaves a team or the organization, you need only to take them out of the relevant Google Groups or Team Drives to also remove their account’s permissions to files. Note that by locking down your files in this way, your system becomes much less widely accessible to staff, and someone will need to be in charge of and regularly available for changes to permissions and group settings as needed. The increased control of your files is well worth this overhead.  It is also useful to be aware that Team Drive permissioning carries other operational tradeoffs around folder structure: it may limit who can create folders and move files around, which can benefit the clarity with which files are organized, but may also run counter to staff expectations and be quite disruptive. More expensive versions of G Suite also include Google Vault, which gives you a more robust set of tools for logging, archiving, and review of organizational documents for compliance or other reasons as described at https://support.google.com/a/answer/2462365.  Turn on two-factor authentication  Turn on two-factor authentication, and, in conjunction with appropriate planning, training, and support, enforce it for all users. Use Google Authenticator codes or universal two-factor (U2F) hardware keys as a second factor rather than text message codes, and make sure staff reports immediately if their second factor is lost or stolen.  One of the advantages of G Suite as a platform is its support for two-factor authentication, whereby users prove their identity at login with two things that they know or control: 1) a password and 2) a hardware key, code produced by a program running on their computer or phone, a text message code, a phone call to a cell or landline, or even a list or codes they have printed out. Unless your organization owns and manages the cell phones that would be receiving a text message or call, it is strongly advised that all staff use a second factor that does not rely on a text message or call to a cell phone when logging into Google services, especially for any accounts with Super Admin or other administrative rights to your G Suite domain. This is because it can be surprisingly easy for someone to take over control of a cell number via social engineering and/or fraud (see https://www.ftc.gov/news-events/blogs/techftc/2016/06/your-mobile-phone-account-could-be-hijacked-identity-thief, https://techcrunch.com/2016/06/10/how-activist-deray-mckessons-twitter-account-was-hacked/, and https://threatpost.com/nist-recommends-sms-two-factor-authentication-deprecation/119507/ for more information).  There are several alternatives to text messaging for this purpose. Google Authenticator is available in the Google Play store for Android phones, in the App Store for iOS devices, and as a Chrome extension for use in the browser. The most common U2F hardware key is called a Yubikey and can be ordered at: https://www.yubico.com/gafw/. Using this link and logging into your G Suite admin account will allow you to order up to 50 keys at the half-price cost of $9 each.  Because of the choices available, the impact of this change on staff members’ daily work, and the consequences of disrupted access to G Suite accounts, careful planning for the rollout of two-factor authentication is essential. Furthermore, enforcing two-factor authentication for all users requires each staff member to participate in this rollout in very specific ways. Refer to all the information and resources below to understand the scope of necessary planning.  Information about setup, as well as links to training materials for staff, is detailed in this document: https://support.google.com/a/answer/175197. Have staff print backup codes (see directions: https://support.google.com/accounts/answer/1187538 so that they can still get into their account if their phone or hardware key is lost or stolen. Although those backup codes will allow them keep working, it is important to train users to report a lost second factor or set of backup codes to whoever is responsible for administration of your G Suite domain. Once reported lost or stolen, a security key must be revoked (https://support.google.com/a/answer/2537800#seckey), backup codes must be regenerated by the user (https://support.google.com/accounts/answer/1187538), or a Google Authenticator app must be removed as a second factor to preserve your security levels. Be aware that separate passwords for applications such as email or calendaring clients that do not support the two-factor process will become necessary, and you will want to be sure you help staff create those as outlined in this document: https://support.google.com/a/answer/1032419.  You can also use the Advanced Security Settings, which can be applied to all of your users, or any group of users in an organizational unit, to require that two-factor authentication is set up within a certain amount of time after a user’s first login. Although this may put a strain on technical support resources, it is highly recommended. Directions to enforce two-factor authentication can be found at https://support.google.com/a/answer/2548882.  Make email spoofing harder  Implement controls that make it difficult for anyone to spoof email from your domain.  Google has produced a strong set of tools to allow other email systems to verify that email coming from your G Suite domain is in fact yours, preventing spoofed emails. (Email spoofing is the creation of email with a forged “from” address, generally sent with the intent to deceive the recipient.) Using them will make it very hard for your email addresses to be abused for phishing or other attacks against external parties, as well as faked internally. These tools use the latest Internet standards called Domainkeys Identified Mail (DKIM), Sender Policy Framework (SPF) records, and the associated Domain-based Message Authentication, Reporting &amp; Conformance (DMARC) records to do this. Documentation that will guide you through setting them all up is at https://support.google.com/a/topic/4388154.  Setting up DKIM, SPF, and DMARC is a highly technical set of tasks that involves your Domain Name Servers (DNS) in addition to Google. Your DNS may not be hosted at Google and so may require a different login; the management tools and may not have an easy interface to work within. It may be more appropriate to assign this set of tasks to your tech support provider than to do it yourself.  SPF records identify which mail servers are permitted to send email on behalf of your domain. Be aware that setting this up requires identifying all the services that are currently sending email on your behalf (which could be databases, mass mailing tools, email list hosts, fundraising tools, and more); incorrect configurations can cause your email to be incorrectly marked as spam. Determining this list carefully is critical to implementing this recommendation in a way that does not interrupt ongoing operations. “Hard fail” settings (records ending in “-all”) are preferred for SPF records wherever possible, but be careful, as this can cause email bounces if your records are not carefully tuned. Once set up correctly, however, you will need to maintain this list and make changes any time your organization adopts any other tools that send email from the same domain as your email addresses. Other than these maintenance steps, this should be invisible in operation.  Disable forwards  Disable users’ ability to set up automatic email forwarding on their account, so that any sensitive internal emails don’t end up traveling insecurely to other email accounts or remain in less-secured email systems that are vulnerable to attack.  Although it can be handy for people to be able to forward their organizational email automatically to personal or other email accounts, your organization has no control over how that email travels and how secured it is once it gets there. By allowing automatic email forwarding to other systems, you create a point of potential disclosure for internal conversations that would be otherwise locked into Google’s secured infrastructure and (assuming you follow this checklist in full) protected by strong passwords and two-factor authentication. This is a simple setting that can be applied to all users or a set of users in an Organizational Unit as detailed at https://support.google.com/a/answer/2491924. Note this does not prevent a user from forwarding emails manually, emailing copy and pasted emails, screenshots, or downloaded copies of an email outside of your organization, so is best coupled with clear policies and guidelines in this area.  Change sharable links settings  Change the default behavior of the “Get sharable link” feature.  Unless you change the default behavior of your G Suite, whenever anyone clicks “Get sharable link” on a folder or file, they will create a link that is open to anyone, without needing to sign into a Google account. You can and should change this default behavior so that “Get sharable link” can be used to copy-paste a document link without changing the existing permissions on the item. Instructions for finding these settings are at https://support.google.com/a/answer/60781?hl=en; under Link Sharing, choose “OFF.” This setting will not prevent files and folders from being shared more widely by intentionally changing the item’s permissions via the “Share” button.*  Education  Educate your staff on file sharing, including the higher security of sharing by email address and risks associated with sharing files by link.  All users should be trained on the exact options available to them for sharing files in G Suite both with coworkers and external partners. This help document provides a good overview: https://support.google.com/drive/answer/2494822. Though this article is clear, helpful, and very suitable for end users, document sharing and collaboration work flows can be complex; it is recommended to document some guidelines based on your organization’s specific ways of working and then offer in-person or webinar trainings, with live practice, to develop shared understanding and strong usage practices among staff.  The tightest control over sharing is exercised by clicking the “Share” button and filling out the “People” field with email addresses associated with Google-based accounts, whether inside your domain or not. When sharing in this way, you can copy the link from your address bar and share it safely, as it will remain accessible only to those with whom it has been shared. (Unless your G Suite’s default behavior has been changed as detailed in the above item, clicking “Get sharable link” will change the permissions so that anyone with the link can view, without logging in.)  Situations will inevitably arise where a broadly accessible link is necessary (for example, if your external collaborator does not have a Google account or you want to cast a wide net for feedback). Be sure to consider the sensitivity of the document in these situations, and, when you choose to share this way, watch out for accidentally making a file public–be sure to choose “anyone with the link” instead. You should also train users to set an expiration date on shared links, even if it is far in the future. This will ensure that the file or folder in question eventually becomes unshared. Last but not least, it is important to choose the most limited permissions appropriate–allowing people who do not need to change its contents only to view and comment on a file.  Responsibilities  Make sure someone is assigned to regularly monitor what is happening in G Suite, has time to do so, and knows how to identify and escalate any security incidents or other concerns about abnormal usage.  Reporting on what is happening with your organizational tools and information over time is an important security practice. This is true for all tools, and an advantage of G Suite is that it makes this kind of reporting more accessible than in other tools. You want one individual or a team tasked with this ongoing monitoring, even if it’s an external tech support provider, so that problems are caught quickly. Monitoring should be done on a schedule, no less than a monthly and preferably more often. To sustain this practice, it is essential that the person, team, or external provider is assigned this task via their workplan or scope of work. The goal of monitoring is to find unusual behavior, such as sudden growth in file sets or email activity, so the responsible party should first establish a baseline of normal activity and then look for trends outside of that baseline. Any questionable activity should be investigated with the users whose accounts are involved, or escalated to a tech support professional.  Activity Reports are available inside the administrative console, including use of two-factor authentication, external apps installed, emails sent/received, and file activity in Google Drive. An article describing these basic reports is at https://support.google.com/a/answer/4580176. A broader explanation of all the reporting available to you in G Suite can be found at https://support.google.com/a/answer/6000239.  In addition to this activity monitoring, it is important to regularly review the security settings of your users, especially password strength for any users not enrolled in two-factor authentication, as described here: https://support.google.com/a/answer/2537800#password. Google is continually updating their password-strength rating system in response to leaked passwords and other emerging threats, so a password that is judged strong one week may be judged weak the next. (This is less important for users with two-factor authentication, because in those cases as their password is only half of what is needed to access their account.) When you see a weak password in your systems, it should be changed. If you have regular contact with the user in question, walking them through changing to a better password is the best option. If you don’t have regular access or they don’t use the systems regularly, you can reset the password (using these directions: https://support.google.com/a/answer/33319?hl=en) so the account is protected, and communicate the new password to them via a secure channel; if you don’t have a secure channel through which to give them their new password, you can reset the password and let them know that they should go through the “forgot password” process the next time they need to log in (be sure to follow up to make sure the new password they choose is strong enough). If appropriate to your operations and the frequency of their use of the account, you can also suspend the account and reenable it as needed (https://support.google.com/a/answer/33312?hl=en).  Avoid “don’t ask again”  Train users not to check the “Don’t ask again on this computer” checkbox when using public or other untrusted computers, to logout after using such computers, and to untrust computers that are lost, stolen, or otherwise compromised.  This practice will help ensure that all your other efforts to create high barriers to accessing your information are successful. When a user checks the “Don’t ask again on this computer” box when logging into G Suite with two-factor authentication, they are telling Google not to ask for a password or second factor for 30 days. In the case of a poorly managed (i.e., not regularly cleaned or reset) computer in a library, Internet café, or other public place, this leaves an account wide open to abuse during that period. Though Google will prompt again for password changes and other sensitive actions, that computer retains the ability to access account information, send emails, and read and edit documents. Trusted computers can always be reviewed, and trust revoked, within a user’s account settings as detailed here: https://support.google.com/accounts/answer/2544838.  See Also     Security Education Companion / Locking Down Social Media   Security In-a-box / Protect Yourself and Your Data When Using Social Networking Sites   Security Self-defense / Facebook Groups: Reducing Risks   Security Self-defense / Protecting Yourself on Social Media   Security Planner / Security Checkups   Security Planner / Privacy Settings   Security Planner / Password Alert"
},{
  "title": "Contributing",
  "url": "/contributing.html",
  "tags": "",
  "content": "Simple method: editing on Github  Learning to use git can be very difficult. As an alternative, it is possible to contribute to security.git by directly editing pages through the Github website. This method does not let you preview how the page will render, but it does allow you to contribute edits without needing to install any software.  First, you need to register a github.com account. Then visit github.com/thoughtworks/security.  To edit files:     Existing Files: You can edit an existing file by clicking on the file name and then clicking the “Edit” button in the file’s toolbar (it looks like pencil). To save, type a commit message and hit the “Propose file change” button.   New Files: You can add a new page by clicking the “+” button at the end of the path breadcrumbs (e.g. “security / pages / netsec / [+]” near the top of the page). When you are done editing the content, hit the “Propose new file” button.   Boom, you are done. Someone will review the change request and either merge it right away or add comments.  Advanced method: using git and Jekyll  Clone the repository          Fork the project repository by clicking on the ‘Fork’ button near the top right of the page. This creates a copy of the code under your GitHub user account. For more details on how to fork a repository see this guide.           Clone your fork of the security repo from your GitHub account to your local disk:      $ git clone git@github.com:YOUR_GITHUB_LOGIN/security.git $ cd security                Create a feature branch to hold your development changes:      $ git checkout -b my-feature                Modify the pages in your feature branch. Add changed files using git add and then git commit files:      $ git add modified_files $ git commit           Then push the changes to your GitHub account with:      $ git push -u origin my-feature                Issue a pull request      Go to https://github.com/YOUR_GITHUB_LOGIN/security and push the button to issue a pull request. Someone will review your changes and merge them or comment on them.  Installing Jekyll  In order to preview your edits before you commit them, you will need a program called jekyll.  Install bundler for Mac:  $ brew install ruby $ gem install bundler   Install bundler on Debian/Ubuntu:  # apt install ruby ruby-dev build-essential # gem install bundler   Install jekyll:  $ cd security $ bundle   Previewing pages  When you are making changes, you can prevew the changes by running the jekyll server:  $ cd security $ make serve   Then browse to http://localhost:4000. Any page you view this way gets re-rendered when it is loaded.  After you have made changes, run this command to completely render the static HTML for the entire site:  $ cd security $ make build   Putting it all together     Go to https://github.com/securityguide/securityguide and click the fork button.   Clone your fork locally: git clone ssh://git@github.com/YOUR_GITHUB_LOGIN/security   Start the amber server: cd security; make serve   Edit files in security/pages   Preview changes in your browser using http://localhost:4000   When satisfied, git commit, git push   Go to https://github.com/YOUR_GITHUB_LOGIN/security and push the button to issue a pull request.   Keeping up to date  After a while, your fork of the repo will become out of date. In order to refresh it with the lastest upstream content:  $ git remote add upstream https://github.com/securityguide/securityguide $ git checkout master $ git fetch upstream $ git rebase upstream/master   Editing tips  Syntax  These pages use Markdown syntax (Kramdown flavored).  Wiki links  In addition to traditional Markdown syntax for links, you can use wiki-style links, like so:  \\[[page_name]] \\[[page_name|Title]] \\[[Title =&gt; page_name]]   Using wiki-style links is highly preferred, because these links will not break when a page moves and missing links will produce an error notice.  Includes  You can mix in Liquid tags in your Markdown pages. For example, this text:     {% include blah.md %}   Will insert the contents of pages/_includes/blah.md into the current page.  To include a formatted code block:     ```bash  {% include script.sh %}  ```   Additionally, you can include any page in another page via the include_page plug in:     {% include_page secret_management %}   This will insert the contents of secret_management.md into the current page, regardless of where the file secret_management.md lives in the directory structure.  Navigation menu  To update the left side navigation menu, edit the file pages/_data/menu.yml."
},{
  "title": "Content Security Policy",
  "url": "/webappsec/best-practices/csp.html",
  "tags": "",
  "content": "Description  Content Security Policy limits the resources that a web browser will load, making it more difficult for attackers to carry out a Cross Site Scripting attack.  When enabling CSP, we can define a whitelist of resources that the browser will load. Any resources (even including inline scripts) that are not explicitly enabled in the whitelist will be blocked by the browser.  As an exploit mitigation, it’s important to remember that while CSP makes exploitation more difficult, it does not prevent the bugs that make an exploit possible in the first place (lack of appropriate encoding/sanitization). Therefore, its protection will never be complete, and people will continue to find bypasses for even the most rigerous policies. That said, it’s an important part of a Defense in Depth strategy for any web application.  Acceptance Criteria     A policy is created that blocks any resources not required by the application   The policy is enabled via the Content-Security-Policy header   An api or service is created to parse CSP reports   Reporting is enabled via the report-uri directive   The team understands what limitations CSP adds, and how to check for violations   The team has a process for updating the policy as requirements change   Resources     https://scotthelme.co.uk/content-security-policy-an-introduction/   https://developers.google.com/web/fundamentals/security/csp/"
},{
  "title": "Dependency Checker",
  "url": "/webappsec/best-practices/dependency-check.html",
  "tags": "",
  "content": "What is it?  A dependency checker is a tool that attempts to detect when updates are available for third party dependencies (libraries, frameworks, etc) used in your application due to publicly disclosed security vulnerabilities.  Why is it needed?     Up to 90% of many applications are comprised of third party components.   Applications often inadvertently introduce vulnerabilities by failing to update components in a timely manner or by pulling in outdated components with vulnerabilities.   When should I use this?  All the time.  Using components with known vulnerabilities is a widespread and serious problem in application development. It can lead to easy, scannable vulnerabilities in your app. Recommended tools for a variety of languages are provided elsewhere in this project:  Tools     [[agnostic-dependency-checker]]   [[java-dependency-checker]]   [[javascript-dependency-checker]]   [[python-dependency-checker]]   [[ruby-dependency-checker]]   Further reading     https://www.owasp.org/index.php/OWASP_Dependency_Check"
},{
  "title": "Device Encryption",
  "url": "/opsec/level-one/device-encryption.html",
  "tags": "",
  "content": "Why Use Device Encryption?  Full disk encryption means that the contents of a disk, usually the storage inside your device–which contains the operating system, programs you have installed, and your organizational data–are scrambled so that they cannot be easily accessed when the device is off.  Without this feature, someone who steals your device, finds your lost device, or otherwise accesses your hardware can easily read your files and possibly impersonate you to your systems. Even worse, an attacker can install malware that allows them to remotely access all your activities.  How-to Enable Device Encryption  Although full disk encryption is enabled by default on some mobile devices, it must be manually set up on all laptop and desktop computers, and many phones and tablets.  Desktop How-to:     Security Planner / Windows Encryption   Security Planner / Mac Encryption   Mobile How-to:     Security Planner / Apple iOS Encryption   Security Planner / Android Device Encryption   Device Encryption Caveats  Authentication Must Be Enabled Device encryption is not effective unless the device requires authentication to use. For example, you are required to log in when using your laptop or provide a PIN when using your mobile device.  Can Be Slow It is important to know that full disk encryption requires your device to do complex math, so turning on this feature will use processing power and may even make very old devices unreasonably slow to use.  Makes Disk Recovery Impossible Full disk encryption can also increase the risk of you losing access to some of your information if robust password- or PIN-management practices are not in place. A lost password or PIN as well as failure of the part of the disk where the encryption keys are stored will generally mean you (as well as anyone else) cannot recover your data. Ensure that you use syncing services and/or have regular backups of your data to minimize the risk of data loss.  Device Must Be Off or Locked Full disk encryption provides protection only when your computer is turned off, or turned on but awaiting a password to start up. Once you have logged in, the computer has the secret key needed for decrypting your data in its memory (so you can work!) and so even with the screen locked there is some risk of someone obtaining access to the contents of your computer while it is running or even sleeping. However, in general, surmounting those controls is a highly technical attack and that risk shouldn’t stop you from keeping your computer turned on or logged in when you need to work. It is, however, best to to turn off your devices whenever your device will be away from you in a hostile environment.  See also     Security In-a-box / Secure File Storage   Security Planner / Windows Encryption   Security Planner / Mac Encryption   Security Planner / Apple iOS Encryption   Security Planner / Android Device Encryption   Security Self-defense / How to: Encrypt Your iPhone"
},{
  "title": "Device Settings",
  "url": "/opsec/level-two/device-settings.html",
  "tags": "",
  "content": "Set devices to lock themselves  What?  Always set up a long (8 numbers or more) PIN code or complex password (longer than 12 characters) to log in to any device–computer, phone, or tablet.  Why?  This ensures that a lost or stolen device is inaccessible through its screen and the hardware remains encrypted. Use the screen timeout feature of your device and require your password or PIN to wake it back up to ensure that your information and your accounts are protected even if the device is found while turned on.  How?     macOS: Apple menu &gt; System Preferences &gt; Security &amp; Privacy &gt; General, then select Require password.   Windows:   Android: Settings &gt; Lock screen &gt; Select screen lock (varies for different Android versions).   iOS:   The shorter the screen timeout period, the shorter the amount of time your device is vulnerable–so choose as short a time as you can while still being able to do your work.  If stepping away from a device, manually lock the screen. Nearly every computer operating system has a keyboard shortcut or other quick way to lock a device (look it up in the relevant documentation or ask your technical support provider).  Caveats  Public spaces: Be aware when entering a PIN or password in public spaces to be sure nobody malicious is watching and that your keystrokes are not being recorded on camera.  Biometrics: For mobile devices, biometric unlocking mechanisms (for example, fingerprints or facial recognition), swipe patterns, and other locking mechanisms are becoming more common, and are generally easier to use than complex passwords and long PINs. However, they can be more easily bypassed by, for example, grabbing your wrist and forcing your thumb into the button, holding your phone up to your face, or looking at the pattern of skin oils on your screen to see a swipe pattern. For these reasons they are not recommended. This may change as implementations improve.  Turn off built-in file sharing  What?  Why?  Although handy for sharing files with peers, the built-in file sharing functionality on your device is vulnerable to abuse or accidental information leakage, especially on simple networks like one finds in cafés or on airplanes, which don’t provide host isolation (the lack of host isolation means that any device using the wireless can connect to any other device). It is preferable to set up alternate tools and practices for sharing files, such as a central file repository in your office or a an Internet-based file service.*  How?  To turn off file sharing on a Mac, go to Apple menu&gt;System Preferences, then click Sharing and make sure all the boxes are unchecked. Also disable AirDrop on your computer by going to the Finder, and choosing AirDrop under the Go menu. When the window comes up, you will see the phrase “Allow me to be discovered by” with a dropdown menu for completion. Choose “No One” from this dropdown. On an iOS device, select “Receiving Off” in the Control Center’s AirDrop settings. See this article (https://support.microsoft.com/en-us/kb/307874) for turning off file sharing on a Windows computer.  Recognize that if you are currently using any built-in file sharing functionality to share files inside an office, doing this will disrupt current work practices.  Turn on firewall  What?  Why?  How?     macOS: Security Planner / Mac Firewall   Windows: Security Planner / Glasswire Firewall   See Also     Security In-a-box / Use Mobile Phones as Securely as Possible   Security In-a-box / Use Smartphones as Securely as Possible   Security Self-defense / The Problem With Smartphones   Security Planner / Find My iPhone   Security Planner / Find My Device (Android)"
},{
  "title": "Email Safety",
  "url": "/opsec/level-one/email.html",
  "tags": "",
  "content": "Never trust the sender  The primary reason that email is the source of most attacks in an organization is that there is no way to verify the identity of the “From” address.  Let’s repeat that: Anyone can spoof the “From” address and can make any email appear to come from anyone else.  Because it is difficult to verify the sender, your inbox is a common source of Phishing Attacks and Malware Attacks.     Phishing Attack is when someone sends an email claiming to be an entity they are not, and uses this deception to get information. They can be after social security numbers, bank information, passwords, or other sensitive information.   Malware Attack is when an attacker attempts to trick you into installing malicious software on your computer when you open an attachment or click on a link.   Generally, anything unexpected in your email should be looked at with suspicion. Be wary of any messages that ask you to do something, including clicking a link, opening an attachment, or emailing back information.  If someone has broken into your account, you may see reply messages you don’t understand, additional sent items, new folders or filters being created, or other changes to settings. Suspicious emails or account behavior should be reported to a technical support person and you should preemptively change your password.  Avoid links in emails  Links, often innocuous looking or even hidden within emails, are a major way adversaries get rogue software inside networks.  The best practice is to never click links in emails. If you must click a link, follow this checklist:     Are you expecting this email? Even if the “From” address appears to belong to someone you know, you should be very cautious when you receive an unexpected email.   Can you manually type the link instead of clicking on it? What you see in the link might not be what the link really is. Domain names can contain “homographs”, or different characters that look the same (e.g. the number “0” and an uppercase “O”, or between Latin and Cyrillic charsets). That link that appears to be https://thoughtworks.com might actually point to an attacker’s website at https://thoughtwоrks.com (the second link uses a Cyrillic letter for the second “o”). The safest way for users avoid this attack is to never copy URLs from unsafe sources and always type URLs to the address bar directly.   Do you recognize the domain? In most email programs, as on the web, hovering over a link displays the URL it points to. If the link’s destination is unexpected or unfamiliar, check with the sender to make sure the email is legitimate. The link should always start with “https://”. If it starts with “data://”, then it is certainly a phishing attack.   Never click on links or open files from unknown senders or in otherwise suspicious emails. Unlike people you know and are working with, someone you don’t know will never send you a file that you actually need; if a link from an unknown sender actually contains useful information, you will be able to access it via another, more trusted method (for example, a web search).  Never log in after clicking a link  If you do click a link in your email, it is very important to not log in to the website that is opened. If the website prompts you to log in, you should instead follow these steps:     Open a new tab in the browser, and type the domain of the website manually.   Using this new tab, log in to the website.   Go back to your email and click on the link again.   When this link opens, it should not require you to log in. If it does require that you log in, then the email is probably a phishing attack.   This practice will protect you from most phishing attacks.  Avoid attachments  Email attachments present several risks, including their use as a mechanism for phishing. They are not protected from being viewed or altered between recipients, so you cannot ensure that the document you send is the same one that the recipient receives. A malicious server between you and the sender could replace it with any program or file they want, including a virus or malware. Additionally, file attachments tend to remain in recipients’ email in-boxes, where they are harder to control. For example, if you filled out an order form using your organizational credit card, and emailed it to a vendor as a PDF, someone who breached their email account would have access to a document containing your credit card information for as long as it was not deleted from the server.  A better practice than email attachments is to have files on a server and send links to documents instead of the documents themselves. Ideally these links lead to locations that themselves are protected by passwords or other authentication, or are temporary and expire soon after use. These links can be easily generated in almost all file-storage systems, whether they use servers in your office (such as a Windows file server) or on the web (such as Google Drive, Box, or Dropbox).  For added security, you can share encrypted files via temporary links by uploading files to https://share.riseup.net.  See also     Security Self-defense / How to Avoid Phishing Attacks   Security Education Companion / Phishing and Malware   Security In-a-box / Protect Your Device From Malware and Hackers   Security In-a-box / Keep Your Online Communications Private   Security Planner / Spot Suspicious Emails"
},{
  "title": "Encrypted Communications",
  "url": "/opsec/level-two/end-to-end.html",
  "tags": "",
  "content": "See Also     Security Education Companion / How to Install Signal   Security Education Companion / End-to-end Encrypted Communications: Phone Apps   Security Self-defense / How to: Use Signal for Android   Security Self-defense / How to: Use Signal for iOS   Security Planner / Signal"
},{
  "title": "Environment Isolation",
  "url": "/webappsec/best-practices/environment-isolation.html",
  "tags": "",
  "content": "No Production Data in Non-production Environments Dev, QA, and staging environments (and their equivalents) often do not have the same care and security measures that are applied to a production environment. Additionally, this is where we do our testing – where we break things and elicit unexpected behavior.  Real Data in App Testing Poses Real Risks The Security Threat From Within"
},{
  "title": "Erasing Data",
  "url": "/opsec/level-three/erasing-data.html",
  "tags": "",
  "content": "Security In-a-box / Destroy Sensitive Information   Security Self-defense / How to: Delete Your Data Securely on Linux   Security Self-defense / How to: Delete Your Data Securely on Mac   Security Self-defense / How to: Delete Your Data Securely on Windows"
},{
  "title": "ExpressJS Pre-flight Checklist",
  "url": "/webappsec/checklists/javascript-checklists/expressjs.html",
  "tags": "",
  "content": "tools  https://www.npmjs.com/package/helmet help secure Express/Connect apps with various HTTP headers  Commercial Tools https://geekflare.com/nodejs-security-scanner/  OWASP Dependency Check  https://jeremylong.github.io/DependencyCheck/dependency-check-cli/index.html  For javascript, you need --enableExperimental  dependency-check.sh --enableExperimental --project 'xxxx' --scan /path/to/project   http://expressjs.com/en/advanced/best-practice-security.html  secure cookie options  const express = require('express') const session = require('express-session')  const app = express() const hour = 3600000 app.use(session({   cookie: { secure: true, sameSite: true, maxAge: hour } }))   secure header options  const express = require('express') const helmet = require('helmet')  const app = express() app.use(helmet())   https://github.com/helmetjs/helmet  csrf  https://www.npmjs.com/package/csurf"
},{
  "title": "Generic Pre-flight Checklist",
  "url": "/webappsec/checklists/generic-checklist.html",
  "tags": "",
  "content": "Configuration  Secrets are stored securely  A “secret” includes passwords, API keys, and private keys.     No cleartext secrets in git   Secrets may be:            Encrypted, (e.g. git-crypt)       Stored in the environment       Stored in secure storage (e.g. credstash)           Anti-CSRF is enabled  When a web browser submits a HTTP request, it dutifully includes all matching cookies, regardless of what web page the request came from. Without CSRF protection, a nefarious page can get your browser to make requests to a protected site while authenticated as you.  Remember:     Idempotent HTTP GET: You must remember to make all GET actions idempotent (does not change the data). This is because the Rails anti-CSRF only applies to HTTP POST.   Images are not protected: Images and other assets are not protected by the Rails anti-CSRF or the same-origin policy. If you have images with sensitive information, then you need an additional system to prevent a third party site from stealing these images.   If the application has a XSS vulnerability, then CSRF is also defeated.   Cookies and sessions     Authentication always triggers a session reset   data in cookies is untrusted, unless signed   sessions have a max lifetime   sessions expire after inactivity   HTTP Headers     Enable secure headers   Sensitive content is not cached   Cache-Control: max-age=0, private, no-store   Secure connections     TLS is required in production   Database connections are secure   Other inputs and outputs   APIs?   Input Validation     Input has restrictive validation   All queries use parameter binding   No mass assignment   Output Filtering     User input is not used to build file paths   All output is filtered, even if the data has been previously validated.   Authorization     Reasonable authentication system   The default is to require authorization   follows principles of least privilege   Pipeline     Dependency checks are run in pipeline   Static analysis is run in pipeline   Routing and URLs     There is no sensitive information in any application URLs   All stylesheets have absolute paths   Documentation     Purpose of application   Security considerations   How application is installed, configured, and run   Logging     Logging is centralized"
},{
  "title": "Enforce HTTPS",
  "url": "/webappsec/best-practices/https.html",
  "tags": "",
  "content": "Protect Data in Transit     Use HTTPS for everything!   Use HSTS to enforce it   You will need a certificate from a trusted certificate authority if you plan to trust normal web browsers   Protect your private key   Use a configuration tool to help adopt a secure HTTPS configuration   Set the “secure” flag in cookies   Be mindful not to leak sensitive data in URLs   Verify your server configuration after enabling HTTPS and every few months thereafter   Enforce HTTPS  Please just do it. Enforcing HTTPS is the best policy, for many many reasons.  Unfortunately, enforcing HTTPS on the server does not not necessarily mean that the browser will not attempt plaintext HTTP connections. If the browser has a session cookie, then these plaintext connection attempts will leak the session to any network observer.  To prevent session hijacking and SSL striping attacks, you need to additional enable the following:     Ensure that the [[Secure cookie flag is set =&gt; abusing-cookies]].   Ensure that HTTP Strict Transport Security (HSTS) is set.   Understanding X.509  To be written  Recommended configuration  Web server configurations that enforce HTTPS and also use a good cipher list.  Apache  &lt;VirtualHost *:80&gt;   ServerName DOMAIN   ServerAlias WWW_DOMAIN   RewriteEngine On   RewriteRule ^.*$ https://DOMAIN%{REQUEST_URI} [R=permanent,L] &lt;/VirtualHost&gt;  &lt;VirtualHost *:443&gt;   ServerName DOMAIN   ServerAlias WWW_DOMAIN    SSLEngine on   SSLProtocol all -SSLv2 -SSLv3   SSLHonorCipherOrder on   SSLCompression off   SSLCipherSuite \"ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:DHE-DSS-AES128-GCM-SHA256:kEDH+AESGCM:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:DHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA:DHE-DSS-AES128-SHA256:DHE-RSA-AES256-SHA256:DHE-DSS-AES256-SHA:DHE-RSA-AES256-SHA:AES128-GCM-SHA256:AES256-GCM-SHA384:AES128-SHA256:AES256-SHA256:AES128-SHA:AES256-SHA:AES:CAMELLIA:DES-CBC3-SHA:!aNULL:!eNULL:!EXPORT:!DES:!3DES:!RC4:!MD5:!PSK!aECDH:!EDH-DSS-DES-CBC3-SHA:!EDH-RSA-DES-CBC3-SHA:!KRB5-DES-CBC3-SHA\"    RequestHeader set X_FORWARDED_PROTO 'https'    SSLCACertificatePath /etc/ssl/certs   SSLCertificateKeyFile /path/to/private.key   SSLCertificateFile /path/to/cert.crt    &lt;IfModule mod_headers.c&gt;     Header always set Strict-Transport-Security \"max-age=31536000; includeSubDomains\"     Header always unset X-Powered-By     Header always unset X-Runtime   &lt;/IfModule&gt; &lt;/VirtualHost&gt;   Nginx  To be written  Client certification authentication  To be written"
},{
  "title": "Opsec Level Three",
  "url": "/opsec/level-three/",
  "tags": "",
  "content": "Physical Device Security     Second Factor Authentication     Erasing Data     Tor     OpenPGP"
},{
  "title": "Sysadmin Best Practices",
  "url": "/netsec/best-practices/",
  "tags": "",
  "content": ""
},{
  "title": "Network Security",
  "url": "/netsec/",
  "tags": "",
  "content": ""
},{
  "title": "Web application security fundamentals",
  "url": "/webappsec/fundamentals/",
  "tags": "",
  "content": "These pages cover the core concepts behind the gritty details of how web applications work and common ways that web applications are compromised. For information on how to actually protect against attacks, see Web Application Checklists and Web Application Best Practices.  Security for web applications can feel like an endless pit of distraction: you can always learn more and there are always new attacks. However, learning the core basics of how cookies and javascript work will help you naturally write more secure code and also make you a better web developer.     Abusing Cookies: The surprisingly true tale of how cookies really work and all the ways in which they can be abused by attackers.     Abusing Filesystems     Abusing Input: Don't. Trust. The. User. Ever. That is pretty much it.     Other Tricks"
},{
  "title": "Python Tools",
  "url": "/webappsec/tools/python-tools/",
  "tags": "",
  "content": "Dependency check for Python     Static analysis for Python     Secrets management for Python"
},{
  "title": "Java Tools",
  "url": "/webappsec/tools/java-tools/",
  "tags": "",
  "content": "Dependency check for Java     Static analysis for Java     Secrets management for Java"
},{
  "title": "Javascript Tools",
  "url": "/webappsec/tools/javascript-tools/",
  "tags": "",
  "content": "Dependency check for Javascript     Static analysis for Javascript     Secrets management for Javascript"
},{
  "title": "Ruby Tools",
  "url": "/webappsec/tools/ruby-tools/",
  "tags": "",
  "content": "Dependency check for Ruby     Static analysis for Ruby     Secrets management for Ruby"
},{
  "title": "Agnostic Tools",
  "url": "/webappsec/tools/agnostic-tools/",
  "tags": "",
  "content": "Agnostic dependency check     Agnostic static analysis     Agnostic dynamic analysis     Agnostic secrets management"
},{
  "title": "Web Application Tools",
  "url": "/webappsec/tools/",
  "tags": "",
  "content": "Tools by languages     Agnostic: Web application security tools that work with all languages    Agnostic dependency check     Agnostic static analysis     Agnostic dynamic analysis     Agnostic secrets management     Java: Web application security tools for Java    Dependency check for Java     Static analysis for Java     Secrets management for Java     Javascript: Web application security tools for Javascript    Dependency check for Javascript     Static analysis for Javascript     Secrets management for Javascript     Python: Web application security tools for Python    Dependency check for Python     Static analysis for Python     Secrets management for Python     Ruby: Web application security tools for Ruby    Dependency check for Ruby     Static analysis for Ruby     Secrets management for Ruby   Dependency check  What is it?  A dependency checker is a tool that attempts to detect when updates are available for third party dependencies (libraries, frameworks, etc) used in your application due to publicly disclosed security vulnerabilities.  Why is it needed?     Up to 90% of many applications are comprised of third party components.   Applications often inadvertently introduce vulnerabilities by failing to update components in a timely manner or by pulling in outdated components with vulnerabilities.   When should I use this?  All the time.  Using components with known vulnerabilities is a widespread and serious problem in application development. It can lead to easy, scannable vulnerabilities in your app. Recommended tools for a variety of languages are provided elsewhere in this project:  Tools     [[agnostic-dependency-checker]]   [[java-dependency-checker]]   [[javascript-dependency-checker]]   [[python-dependency-checker]]   [[ruby-dependency-checker]]   Further reading     https://www.owasp.org/index.php/OWASP_Dependency_Check   Static analysis  What is it?  A static analysis tool, referred to as a Static Application Security Tool (SAST) in the context of security, identifies potential security flaws in source code, byte code, and binaries. SAST tools provide a powerful way to identify potential defects by analyzing applications from the “inside out”. This provides much greater sight into possible flaws than a scanner that only interacts with a application as a user would.  Why is it needed?     Sometimes the easiest or most obvious way to do something is also not secure. These tools provide fast feedback if a mistake is made.   Continuous, fast feedback about potential vulnerabilities saves teams time and stress.   When should I use this?     In your CI pipeline. Automatically run the scanner periodically, possibly alongside other automated tests following a checkin if it can complete quickly enough.   During manual testing. More in-depth scans can be run and verified along with the other necessary manual tests. Testers can also start to do some exploratory security testing after familiarizing themselves with typical weaknesses.   Tools     [[agnostic-static-analysis]]   [[java-static-analysis]]   [[javascript-static-analysis]]   [[python-static-analysis]]   [[ruby-static-analysis]]   Further reading     Wikipedia page on static program analysis   Wikipedia list of static program analyzers   OWASP wiki page on static program analysis   NIST list of security-focused static program analyzers   Dynamic analysis  To be written  Secret management  What is it?  Secrets such as passwords, credentials, access tokens, certificates, and other confidential information are something we can’t allow to fall into the wrong hands. A secret management tool makes it possible to manage these kinds of secrets safely.  Why is it needed?  We see this more than you’d think. The dangers of leaving secrets into your code are wide ranging and severe. It could lead to everything from an attacker compromising a user’s session to full owning your application, and even the application server, gaining access to your database, and impersonating you to uncover more valuable data (and this is not an exhaustive list).     Applications rely on secrets to access services such as databases, encrypted files, and to securely communicate with other applications and systems.   Team members may also need a way to manage and share similar confidential information.   Writing secrets in a place they can be easily retrieved exposes projects to unnecessary risks. This includes doing things like writing them on sticky notes or in source code or configuration files.   Tools     [[agnostic-secrets-management]]"
},{
  "title": "Ruby Checklists",
  "url": "/webappsec/checklists/ruby-checklists/",
  "tags": "",
  "content": "[[rails-4]]   [[rails-5]]"
},{
  "title": "Javascript Checklists",
  "url": "/webappsec/checklists/javascript-checklists/",
  "tags": "",
  "content": "Platforms     [[expressjs]]   [[nodejs]]   Secure Coding Practices  Avoid stringify()  The command JSON.stringify() is not safe and can lead to XSS attacks.  Instead, use serialize-javascript:  $npm install --save-dev serialize-javascript      View on GitHub   Security risk details   Resources &amp; Advisories  https://medium.com/node-security"
},{
  "title": "Web Application Checklists",
  "url": "/webappsec/checklists/",
  "tags": "",
  "content": "Generic     Ruby    Rails 4     Rails 5     Javascript    NodeJS     ExpressJS   TODO: add acceptance criteria for major items, such as dependency check, static analysis, and secrets storage."
},{
  "title": "Tutorials",
  "url": "/webappsec/tutorials/",
  "tags": "",
  "content": "SAML with Ruby: How to add Okta SAML authentication to Ruby applications"
},{
  "title": "Web Application Best Practices",
  "url": "/webappsec/best-practices/",
  "tags": "",
  "content": "Validate User Input     Dependency Checker     Static analysis     Secrets Management     Access Controls     Content Security Policy     Environment Isolation     Enforce HTTPS     Logging"
},{
  "title": "Web Application Security",
  "url": "/webappsec/",
  "tags": "",
  "content": "Contents     Fundamentals: The core concepts behind the gritty details of how web applications work and common ways that web applications are compromised.    Abusing Cookies     Abusing Filesystems     Abusing Input     Other Tricks     Checklists: Essential things to check before deploying your web application into production.    Generic     Ruby     Javascript     Best Practices: A guide to the best practices when writing web applications.    Validate User Input     Dependency Checker     Static analysis     Secrets Management     Access Controls     Content Security Policy     Environment Isolation     Enforce HTTPS     Logging     Tools: Tools to help you write more secure web applications.    Agnostic     Java     Javascript     Python     Ruby     Tutorials    SAML with Ruby   Tasks     Read the fundamentals   Work through the checklist for your platform   Read the best practices   Use the tool section as a resource"
},{
  "title": "Opsec Level One",
  "url": "/opsec/level-one/",
  "tags": "",
  "content": "Passwords: Better living through better passwords.     Email Safety: Simple tips for using email safely.     Device Encryption: The how and why of encrypting your device's storage.     Better Browsing: Adjust your web browser for greater security.     Software Best Practices: Best practices for installing and updating software."
},{
  "title": "Opsec Level Two",
  "url": "/opsec/level-two/",
  "tags": "",
  "content": "Device Settings     Cloud Settings     Backups     Mindfulness     Encrypted Communications     VPN"
},{
  "title": "Operations Security",
  "url": "/opsec/",
  "tags": "",
  "content": "Level One: Start here! Easy steps that everyone can take to make their computing more secure.    Passwords     Email Safety     Device Encryption     Better Browsing     Software Best Practices     Level Two: Once you have mastered the basics, take on these personal security best practices.    Device Settings     Cloud Settings     Backups     Mindfulness     Encrypted Communications     VPN     Level Three: Advanced topics for the aspiring security maven.    Physical Device Security     Second Factor Authentication     Erasing Data     Tor     OpenPGP   Credits  Some text adapted from:     Digital security checklists for US Non-profits   from Information Ecology, by Jonah Silas Sheridan, Lisa Jervis (Creative Commons: Attribute-ShareAlike)   Security Planner   from Citizen Lab (Creative Commons: Attribution)   Surveillance Self-defense   from Electronic Frontier Foundation (Creative Commons: Attribution)   Security Education Companion   from Electronic Frontier Foundation (Creative Commons: Attribution)   Security In-a-box   from Tactical Technology Collective (Creative Commons: Attribution-ShareAlike)"
},{
  "title": "Validate User Input",
  "url": "/webappsec/best-practices/input.html",
  "tags": "",
  "content": "https://martinfowler.com/articles/web-security-basics.html  Reject Unexpected Form Input     White list when you can   Black list when you can’t whitelist   Keep your contract as restrictive as possible   Make sure you alert about the possible attack   Avoid reflecting input back to a user   Reject the web content before it gets deeper into application logic to minimize ways to mishandle untrusted data or, even better, use your web framework to whitelist input   Encode HTML Output     Output encode all application data on output with an appropriate codec   Use your framework’s output encoding capability, if available   Avoid nested rendering contexts as much as possible   Store your data in raw form and encode at rendering time   Avoid unsafe framework and JavaScript calls that avoid encoding   Bind Parameters for Database Queries     Avoid building SQL (or NoSQL equivalent) from user input   Bind all parameterized data, both queries and stored procedures   Use the native driver binding function rather than trying to handle the encoding yourself   Don’t think stored procedures or ORM tools will save you. You need to use binding functions for those, too   NoSQL doesn’t make you injection-proof   Validate User Inputs  If you have fields that accept user input in your application, making it a priority have some validations on this input is imperative to a basic level of security on your application.  An excellent blog post by Cade Cairns and Daniel Somerfield outlines some of the dangers of accepting as-is user input, along with some mitigation strategies.  Here are some of the main takeaways:     Accepting unvalidated input can lead to an attacker taking control of the app itself.   Setup alerts for potential attacks.   Whitelist (positive validation) expected inputs over blacklisting a set of known unwanted inputs (negative validation). Make your whitelist strict.   “Resist the temptation to filter out invalid input” aka “sanitization”. Reject invalid input altogether.   In a similar vein (and in the same blog post), take care to encode HTML output as well."
},{
  "title": "Dependency check for Java",
  "url": "/webappsec/tools/java-tools/java-dependency-checker.html",
  "tags": "",
  "content": "dependency-check  This dependency checker from OWASP is widely used and actively developed. It is compatible with Java/.NET, and there is currently experimental support other languages including Python.  Installation  There are a few ways to install dependency-check, but our best experience has been installing with Homebrew:  $ brew update &amp;&amp; brew install dependency-check   You can also download the dependency-check-cli zip file.  Usage  Dependency-check requires two arguments:     --scan (path to project you would like to scan)   --project (choose the name you would like for your project)   Check out the --advancedHelp option for some very specific options that could be well-suited to your project.  With Python projects, it is advisable to use the --enableExperimental flag since the features that scan Python files are still considered experimental by the Dependency Check project (don’t worry, we’re pretty confident in it regardless).  By default, the HTML report will be saved to whatever directory you are in when you run the scan. This file will be overwritten if no -o/--output or -f/--format are specified. Keep this in mind if you integrate this into your pipeline (as we hope you do!).  Documentation  The full documentation and the latest downloads can be found at: https://jeremylong.github.io/DependencyCheck/index.html  CI Integration  Some basic best practices/guidelines for adding OWASP Dependency Check to your CI pipeline can be found here: https://github.com/cairnsc/security-playbook/blob/master/tooling/dependency-checker/owasp-dependency-check.md"
},{
  "title": "Secrets management for Java",
  "url": "/webappsec/tools/java-tools/java-secrets-management.html",
  "tags": "",
  "content": "To be written"
},{
  "title": "Static analysis for Java",
  "url": "/webappsec/tools/java-tools/java-static-analysis.html",
  "tags": "",
  "content": "To be written"
},{
  "title": "Dependency check for Javascript",
  "url": "/webappsec/tools/javascript-tools/javascript-dependency-checker.html",
  "tags": "",
  "content": "NSP  Node Security Project (nsp) checks the dependencies in your project’s package.json against libraries of known vulnerabilities. If your project uses vulnerable versions of a dependency, it will let you know and provide helpful details.  Installation  $ npm install --save-dev nsp  Usage  Running $ nsp check inside your project will generate a well formatted report in stdout  You can of course us the -o/--output option to write the results to a file.  CI Integration  Some basic best practices and guidelines for adding nsp to your CI pipeline can be found here: https://github.com/cairnsc/security-playbook/blob/master/tooling/dependency-checker/npm-dependency-checkers.md  check-dependencies  At the moment, we’d really recommend nsp – it’s a great tool! But if that doesn’t work for your project, here are some alternatives.  npm install --save-dev check-dependencies   and then use exactly as you’d think :)"
},{
  "title": "Secrets management for Javascript",
  "url": "/webappsec/tools/javascript-tools/javascript-secrets-management.html",
  "tags": "",
  "content": "To be written"
},{
  "title": "Static analysis for Javascript",
  "url": "/webappsec/tools/javascript-tools/javascript-static-analysis.html",
  "tags": "",
  "content": "eslint  Installation  $ npm install --save-dev eslint eslint-plugin-security eslint-plugin-scanjs-rules eslint-plugin-no-unsafe-innerhtml   Configuration  Here is a sample .eslintrc.json file, for use with those plugins:  {     //adjust these as necessary for your application     \"env\": {         \"es6\": true,         \"node\": true     },     //uncomment this line if you are getting errors like \"Parsing error: Unexpected token\"     //\"parser\": \"babel-eslint\",     \"parserOptions\": {         \"ecmaFeatures\": {             \"jsx\": true         },         \"sourceType\": \"module\"     },     \"plugins\": [         //\"react\",         \"no-unsafe-innerhtml\",         \"security\"     ],     \"rules\": {     /** useful rules from eslint, if you want them **/      /** security plugin rules **/     \"no-unsafe-innerhtml/no-unsafe-innerhtml\" : 2,     \"security/detect-non-literal-fs-filename\": 2,     \"security/detect-non-literal-regexp\": 2,     \"security/detect-unsafe-regex\": 2,     \"security/detect-buffer-noassert\": 2,     \"security/detect-child-process\": 2,     \"security/detect-disable-mustache-escape\": 2,     \"security/detect-eval-with-expression\": 2,     \"security/detect-no-csrf-before-method-override\": 2,     \"security/detect-non-literal-require\": 2,     \"security/detect-object-injection\": 2,     \"security/detect-possible-timing-attacks\": 1,     \"security/detect-pseudoRandomBytes\": 2   } }   Alternately, you can run $ eslint --init with your project-specific details and include the plugins and rules from our config file.  If you are using the eslint specific to your project, you might have to run $ ./node_modules/eslint/bin/eslint.js --init. This will result in many non-security related linting rules which you can disable by commenting out \"extends\": \"blah\", in the .eslintrc file generated by your init.  You might want to create a file called .eslintignore (or something) containing the line node_modules/. You can then specify the option --ignore-path .eslintignore when you run eslint. This will save you a lot of false positives.  Usage  For a quick start, try:  $ cd my_project $ eslint .   To create an HTML output file you can view in your browser, try:  $ eslint --ignore-path .eslintignore -f html -o eslint-report.html ."
},{
  "title": "Logging",
  "url": "/webappsec/best-practices/logging.html",
  "tags": "",
  "content": "Enable Logging Logs can help you detect and respond to potential malicious behavior in your application.  OWASP Logging Cheat Sheet AWS CloudTrail"
},{
  "title": "Mindfulness",
  "url": "/opsec/level-two/mindfulness.html",
  "tags": "",
  "content": "See Also          Security Education Companion           Mindfulness            be suspicious                    phishing           links           asks for information                       limit personal information sharing"
},{
  "title": "NodeJS Checklist",
  "url": "/webappsec/checklists/javascript-checklists/nodejs.html",
  "tags": "",
  "content": "To be written"
},{
  "title": "OpenPGP",
  "url": "/opsec/level-three/openpgp.html",
  "tags": "",
  "content": "OpenPGP            Security Self-defense / An Introduction to Public Key Cryptography and PGP       Security Self-defense / How to: Use PGP for Linux       Security Self-defense / How to: Use PGP for macOS       Security Self-defense / How to: Use PGP for Windows           :heavy_check_mark:      Use encryption, preferably “end to end,” to secure your email. :rocket: :rocket: :rocket: :rocket: :wrench: :wrench: :wrench: :wrench: :fire: :fire: :fire: :fire: This is a highly technical and labor-intensive initiative to undertake, but is probably the most complete way to minimize any inadvertent disclosure of data through email. Email encryption hides all email content from any servers or network providers that pass your mail along. It will likely require inconvenience for your team and significant changes to staff practices, but it provides strong protection of sensitive information emailed within your organization (and, if it is relevant to you, far greater compliance with standards such as HIPAA). There are various ways to implement email encryption, but only some are truly “end to end,” meaning that you don’t have to trust any parties in the middle, and encryption and decryption only happens on the devices communicating with each other.  The most common type of end-to-end encryption is called Pretty Good Privacy (PGP) and has been around for a long time. Consequently there are a lot of ways to use this type of encryption, and it works across many platforms. (It also lacks the ease and strength of some other, more modern encryption schemes.) One major tool for for using PGP encryption with email is the Mozilla Thunderbird email client (https://www.mozilla.org/en-US/thunderbird/) and the associated Enigmail plugin (https://www.enigmail.net/home/index.php), which works on Windows (with the addition of GPG4Win (https://gpg4win.org/), Mac, and Linux). You can find a guide for the Windows setup at https://securityinabox.org/en/guide/thunderbird/windows. OSX’s built-in Mail program and the open-source add on GPGTools (https://gpgtools.org) is also a workable toolset for using PGP-encrypted email on Macs. Microsoft Outlook works best with a commercial add-on called gpg4o (https://www.giepa.de/products/gpg4o/?lang=en) to use PGP encryption with Microsoft Exchange. Mailvelope https://www.mailvelope.com) is a powerful and well-audited PGP add-on for web browsers that allows you to use PGP encryption with almost any webmail service, including Gmail. Because of its position inside a web browser, its security is generally less assured than the other PGP options above, but is adequate for many organizations, especially when coupled with strong web browser profile controls and careful use of browser extensions as well as other safe browsing practices. Note that as of mid-2017, use of Mailvelope in Firefox is not recommended due to a security vulnerability discovered in it. If you want to use Mailvelope with Firefox, see this blog post (https://www.mailvelope.com/en/blog/security-warning-mailvelope-in-firefox) for details of how to do so as safely as possible.  For organizations with more resources, S/MIME is an alternate encryption scheme that works well with a Microsoft Exchange/Outlook environment or with Gmail by installing the Penango plug-in (https://www.penango.com) or using Google’s native offering (https://support.google.com/a/answer/6374496), which requires use of the G Suite Enterprise paid services.  As alternatives, several third-party-managed encryption tools for email exist. One popular such service is Virtru (https://virtru.com); it is available for Gmail and works best if used only with Gmail users. If you are able to transition your email entirely to their platform, ProtonMail (https://protonmail.com/) is an open source end-to-end encrypted email provider that has implemented common PGP encryption in a package that is easier to use than the toolsets named above and solves a lot of key management problems to make secure email more seamless for users.  Google’s S/MIME option, ProtonMail and Virtru are end-to-end encryption offerings that function with a strong trust dependency on the vendor to produce, manage, and swap encryption keys for seamless emailing. If you are interested in these solutions, be aware that you are entering into a high-trust relationship with the vendor. If wanting to implement any encryption scheme mentioned here for your email, you will need to talk to your technical support provider and be prepared to invest time and resources into planning, implementation, and training."
},{
  "title": "Orphaned Systems",
  "url": "/netsec/best-practices/orphaned-systems.html",
  "tags": "",
  "content": "Try to identify systems that are no longer being cared for and no longer needed. Create a plan for retiring these systems."
},{
  "title": "Other Tricks",
  "url": "/webappsec/fundamentals/other-tricks.html",
  "tags": "",
  "content": "Referrers  There are several things you can do to try to prevent the browser from sending referers          Add the attribute rel=”noreferrer” to links. This only protects links, and is not universally supported by browsers.           Replace links with Data URIs that reload to the new URL, hiding the referer. This only protects links. For example:      &lt;a href=\"data:text/html,&lt;meta http-equiv='refresh' content='0; url=https://example.org'&gt;\"&gt;example.org&lt;/a&gt;      Add a Content Security Policy (v1.1 or later) with a restrictive referer directive. This does not work in all browsers.   These are all good ideas for increasing the user’s privacy, but should not be relied on to mitigate the problems associated with sensitive information in the URL.  Same Origin     Abusing same origin policy            how it works       how it falls down                    CSRF                            different origin writes allowed               tags for: forms, images, assets are allowed                                   dns rebinding                       best pratices           javascript can only phone home   CORS can allow scripts to violate the same origin policy   every javascript that is loaded can read (most) everything on the page and send the information back to its origin.   javascript cannot read ‘tainted’ assets that have been loaded dynamically from different domains."
},{
  "title": "Passwords",
  "url": "/opsec/level-one/passwords.html",
  "tags": "",
  "content": "Use a password manager  The use of a password manager is one of the most important changes you can make to increase your personal security.  A password manager application will allow you to use both strong and unique passwords. With a password manager, you just remember a single password that opens up your secure file or account, which in turn stores all of your other passwords.  There are three important attributes of password managers to be aware of:     local application: a dedicated application that stores its passwords locally on your computer, encrypted using a master password. This is the most secure option, but can be difficult to sync your passwords between multiple devices.   cloud service: a service, typically paid, that stores your passwords for you, regardless of device. You have the added benefit of having access to your passwords wherever you go, at the disadvantage of lower security.   browser plug-ins: Both the application-type and the cloud-type password managers often have plug-ins for web browsers to make your password readily accessible in the web browser. This add convenience, but is slightly less secure.   Regardless of what you choose, what really matters is that you use a password manager.  Popular password managers include:     KeePass and KeePassX (application-type) are two versions of a highly recommended local password manager. These two tools use the same encrypted file format and can run on almost any computer.            Security Self-defense / How to: Use KeepPassXC       Security In-a-box / KeePass overview           LastPass (cloud-type)   1Password (cloud-type &amp; application-type)   Use strong passwords  Strong passwords are randomly generated. Except for the password to unlock your device, and the password to unlock your password manager, all your passwords should be randomly generated by a password manager, and should be at least 12 characters.  Humans are very bad at coming up with secure passwords, but computers are excellent. Let the computer do it for you.  For passwords that you must remember, there are many ways to generate strong passwords. There is a guide in Security In-a-box.  Diceware is a fun and effective scheme for creating random yet memorable passwords using everyday objects and a word list. One other great way to make a strong password is to come up with a silly sentence that no one’s ever said before and use the first letter or two of each word as your password, mixing in other types of characters.*  It is important to apply strong passwords to all accounts, as access to a single account can often be leveraged into access to other systems. This is especially relevant for any email accounts that can be used to reset or recover other passwords (usually via a “forgot password” link).  Use unique passwords  Following this practice is a great way to minimize the risk of using third-party technology services. If you don’t reuse passwords, someone learning your username and password for one service through a leak or break-in won’t make it easy to access the other accounts you use. Use different passwords for each service so you aren’t relying on the services you’re logging into to protect your most important secret.  Keep your passwords secret  Even if someone claims to be from IT or technical support, do not give them your password. Nearly every system allows for administrative reset of passwords for maintenance. Any legitimate IT person can use this function instead of asking you. This system also this creates an auditable trail of access to your account, and alerts you to a reset. You will need to change your password again after such admin access, but taking that extra step will ensure that you and only you have access to your digital information, and that you can know who in your organization is responsible for what changes to your account.  Separate organizational and personal passwords  Organizational passwords include any passwords that grant administrative control of your organization’s information systems or online identity. These are very powerful credentials and so should be stored separately from passwords that just get staff into their personal user accounts. You can do this by making a separate login or file in your password manager application, or by choosing a completely different manager altogether.  Placing organizational passwords in a KeePass or otherwise encrypted file that only a few key staff members can access will lessen the risks of adopting an online password manager for everyday passwords, but will also place a burden on those staff members. Balancing these needs should be factored into your decision.  See also     Security Planner / Password Managers   Security In-a-box / Passwords   Security Self-defense / Animated Overview: Using Password Managers to Stay Safe Online   Security Self-defense / How to: Use KeepPassXC   Security Self-defense / Creating Strong Passwords   Security Education Companion / Passwords   Security Education Companion / Password Managers"
},{
  "title": "Patch Management",
  "url": "/netsec/best-practices/patch-management.html",
  "tags": "",
  "content": "A deliberate patch management plan is required for all service owners and sysadmins.  Although every development team, service owner or system administrator will determine their own particular plan, what is vitally important is that there is a plan in place.  System Patching Standards     Critical/High security updates should be applied as soon as possible but no later than 48 hours after they have been published.   Medium/Low security updates can wait until a standard maintenance window or weekly/monthly scheduled patching.   If possible, package updates should be installed and tested in a test/dev/staging/uat environment before being deployed in production.  Automatic Updates  Windows  Turn on automatic updates.  Mac  Turn on automatic updates.  Linux  RedHat/Centos/Amazon Linux  Method 1  https://www.centos.org/docs/5/html/yum/sn-updating-your-system.html  The yum package supplied with CentOS includes scripts to perform full system updates every day. To activate automatic daily updates, enter this command:  sudo '/sbin/chkconfig --level 345 yum on &amp;&amp; /sbin/service yum start'   Method 2: use “yum-cron” tool  Enabling automatic updates in Centos 6 and Red Hat 6 (yum-cron version 3.2.29 for CentOS 6):  https://linuxaria.com/pills/enabling-automatic-updates-in-centos-6-and-red-hat-6  Automatic updates for CentOS: yum-cron installing and configuring (yum-cron version 3.4.3, for Amazon Linux and CentOS 7): https://jonathansblog.co.uk/yum-cron  Debian/Ubuntu  Install the packages unattended-upgrades and apt-listchanges:  apt-get install unattended-upgrades apt-listchanges      unattended-upgrades will automatically install updates.   apt-listchanges will send you email alerts when there are new versions available (defaults to root).   To test to make sure it will work:  unattended-upgrade -d   For more information, see https://wiki.debian.org/UnattendedUpgrades  Manual Updates  Redhat/Centos  Make sure you have the yum security plugin installed:  # yum -y install yum-plugin-security   Update yum’s metadata:  # yum updateinfo   Check to see what security updates need to be installed:  # yum updateinfo list sec   Install the security updates:  # yum -y update-minimal —security   If you want to install all the available updates, do this:  # yum -y update   Debian/Ubuntu  Manual update:  # apt-get update &amp;&amp; sudo apt-get -y upgrade   Ansible  Syntax to run the playbook manually:  ansible-playbook -i inventory update-machines.yml -u &lt;username&gt; -kK   The inventory file is just a list of machines:  elkkeyrecdb01.thoughtworks.com elkkeyrecdb02.thoughtworks.com elkkeyrecprod01.thoughtworks.com elkkeyrecprod02.thoughtworks.com elkkeyrecstaging01.thoughtworks.com elkkeyrecstaging02.thoughtworks.com   update-machines.yml is the ansible playbook. Here is some sample syntax:  --- - hosts: all   sudo: yes    tasks:     - name: Install security plugin       yum: pkg=yum-plugin-security state=present      - name: Update yum metadata       command: yum updateinfo      - name: See what updates are going to be installed       command: yum check-update --security       register: packageList      - debug: msg=\"The following packages will be updated \"      - name: Install security updates       command: yum -y update --security   Here’s another playbook example:  --- - hosts: all   sudo: yes    tasks:       - name: update all packages         action: yum name=* state=latest"
},{
  "title": "Physical Device Security",
  "url": "/opsec/level-three/physical-security.html",
  "tags": "",
  "content": "Keep your device in your control  The easiest way to attack someone’s devices is to gain physical control of them. Consequently, the most important practice you can follow to protect them is to keep them in your control at all times. This means that you know where they are and can ensure that nobody is accessing them without your permission. When working in a public place, don’t leave any device alone even for a couple of minutes. Aways take your phone with you, and do the same for a laptop. If you have to leave a device someplace, ask someone you trust (not the stranger at the next table!) to supervise it for you to ensure nobody tries to log in or insert any devices into it. This can be inconvenient but ensures nobody can surreptitiously install software on or hardware in your device without your knowledge.  Note: There is a difference between keeping a device safe from theft and in your control. For example, keeping your devices in your locked office building may keep them safe from theft but does leave them accessible to any cleaners who come after hours. Even a hotel room safe can be accessed by the hotel staff. It is impractical to keep your device on your person as all times. (Devices become quite unreliable after being taken into the shower.) So, you should focus on reasonable controls to prevent bad actors from having physical access to your devices. Keeping your device at your home if it is properly secured, or locked in a drawer at night, can provide you a level of security that will force your adversaries to take more extreme means in order to compromise your devices.  Don’t plug it in  Carefully source your USB and memory card devices, only plugging trusted and personally sourced ones into your computer.  Don’t plug other people’s USB devices and memory cards such as flash drives, hard drives, and phones into your computer, or any such devices that came to you in anything other than verifiable original packaging. This recommendation is especially important with regard to devices from unknown or untrusted sources (leaving USB sticks around an office is a classic intrusion technique), but it also applies devices owned by trusted people, as trusting a person is not the same as trusting all the devices they use, the software they run, or the other  devices they have plugged their USB device into into. USB and memory card devices can silently infect your computer in ways that are very hard to detect.  While never plugging USB devices into your computer is ideal, it is not always possible to do so. If you have to plug something into your computer, make sure that computer is running antivirus software that is up to date, and consider logging into a guest account that doesn’t have access to your files or systems and then passing the files on it through an additional virus scan before opening or using. Certain Internet-based services, including Google Drive and Box (but not Dropbox) automatically scan uploaded files (under 25MB for Google Drive) for viruses and will alert you if your files are infected, so you can use that as an additional layer of protection. However, there is still risk associated with USB devices and after using a USB device you don’t trust, be on the lookout for odd behavior such as error messages, extra network traffic, or rapid battery usage and report any of those things to your technical support provider immediately.  Use charge-only cables  Use either a charge-only cable or what is known as a USB condom to charge your device from anything other than a wall charger or a computer that you know to be free of infection. Carry a backup battery to ensure you never have to charge your device from an untrusted source.  Almost all modern professionals have been there: your mobile phone or tablet is dead and the only place to charge it a friend’s laptop, an internet connected device, or a public computer. Unfortunately that computer or device can become a route for a virus or other malicious software to infect your device.  For use in these situations, you can purchase a USB condom (a device that goes in between the USB cable and the port you are plugging into and prevents a connection between the data pins in the unknown port and the USB cable, allowing only the power pins to connect) or charge-only USB cable (which does not contain the wires that are used for data transfer in the first place). Either option will enable you to safely connect your device to any USB port you come across.  Another option, which has the added advantage of being useful even if you can’t find a random port, is to purchase and carry a USB-enabled backup battery so you can always charge your device on the go. Although it has been shown to be possible, there have been no reports of backup batteries spreading malware. However, if charging from an unknown, you may want to use a USB condom or charge-only cable the way you would with an untrusted port to ensure that any software on the battery cannot affect your device.*  See also     Security In-a-box / Protecting Your Information From Physical Threats   Security Self-defense / Things to Consider When Crossing the US Border"
},{
  "title": "Dependency check for Python",
  "url": "/webappsec/tools/python-tools/python-dependency-checker.html",
  "tags": "",
  "content": "Safety  Safety a very strong choice for your Python project. It’s easy to install, easy to use, and accumulates information from several sources to give you as much, or as little information as you need. Not to mention the README comes with a set of instructions for CI Pipeline integration :)  Installation  $ pip install safety   Usage  I find I get the best results when I explicitly tell Safety to look at my requirements file.  safety check -r requirements.txt   This will output the name, installed version, and affected version of the vulnerable dependency.  If you’re looking for more information, you can run a full report:  $ safety check -r requirements.txt --full-report   This outputs the corresponding CVE, descriptions of the issue as collected from multiple sources, and even relevant links to follow for more details.  If you are combining Safety with other vulnerability scanning tools, or if you are using it in your CI pipeline, it might make the most sense to output only the names of the vulnerable packages.  $ safety check -r requirements --bare   Documentation  Check out the GitHub project: https://github.com/pyupio/safety  OWASP Dependency Check  This dependency checker from OWASP is widely used and actively developed. It is compatible with Java/.NET, and there is currently experimental support other languages including Python. Given the experimental nature of the project at this time (July 21, 2017), Safety is likely a better option for your Python project.  Installation  There are a few ways to install dependency-check, but our best experience has been installing with Homebrew:  $ brew update &amp;&amp; brew install dependency-check   You can also download the dependency-check-cli zip file.  Usage  Dependency-check requires two arguments:     --scan (path to project you would like to scan)   --project (choose the name you would like for your project)   Check out the --advancedHelp option for some very specific options that could be well-suited to your project.  With Python projects, it is advisable to use the --enableExperimental flag since the features that scan Python files are still considered experimental by the Dependency Check project (don’t worry, we’re pretty confident in it regardless).  By default, the HTML report will be saved to whatever directory you are in when you run the scan. This file will be overwritten if no -o/--output or -f/--format are specified. Keep this in mind if you integrate this into your pipeline (as we hope you do!).  Documentation  The full documentation and the latest downloads can be found at: https://jeremylong.github.io/DependencyCheck/index.html"
},{
  "title": "Secrets management for Python",
  "url": "/webappsec/tools/python-tools/python-secrets-management.html",
  "tags": "",
  "content": "To be written"
},{
  "title": "Static analysis for Python",
  "url": "/webappsec/tools/python-tools/python-static-analysis.html",
  "tags": "",
  "content": "Bandit  Bandit is a static security analysis tool for Python. Bandit is meant to find the common issues, so please don’t take a passing scan to mean bullet-proof code. You may want to use Bandit in conjunction with a language-agnositc analysis tool like Grepbugs.  Its README.rst is pretty great (somehow both extensive and succinct), so I won’t say too much here.  Installation  pip install bandit f```  ### Usage   bandit -r /path/to/code ```  Some Note  When you have run a scan with bandit, be sure to pay special attention to the following lines in the output:  Code scanned:   Total lines of code: 645   Total lines skipped (#nosec): 0   Make sure those numbers make sense – if you forget to set the -r option, bandit will not scan your project directories recursively.  Similarly, try running bandit with the --verbose option the first time you run it (or whenever you are trying to debug). It lists files included in and excluded from the scan."
},{
  "title": "Rails 4 Pre-flight Checklist",
  "url": "/webappsec/checklists/ruby-checklists/rails-4.html",
  "tags": "",
  "content": "Configuration  The config.force_ssl flag is enabled  In environments/production.rb:  config.force_ssl = true   What this does     This will set a HSTS header in application responses, set the secure flag for cookies, and redirect HTTP to HTTPS.   Why this is important     Even if the web server is configured to require TLS, you probably have a redirect configured from plain HTTP to HTTPS. In these cases, there are many situations where a browser might make a plain HTTP connection attempt, potentionally leaking session information in the clear. By adding an HSTS header and setting the secure flag for cookies, you instruct the browser to always require HTTPS.   Database credentials are stored in the environment  To be written  Anti-CSRF is enabled  Make sure that the top of ApplicationController has protect_from_forgery:  class ApplicationController &lt; ActionController::Base   protect_from_forgery with: :exception end   This is the default when you create a new rails 4 application, but if you upgraded you might not have this.  What this does     Enabling protect_from_forgery will set a value session[:_csrf_token] and include authenticity_token as a parameter to all your POST requests. If the values don’t match, the exception ActionController::InvalidAuthenticityToken is raised.   Why this is important     When a web browser submits a HTTP request, it dutifully includes all matching cookies, regardless of what web page the request came from. Without CSRF protection, a nefarious page can get your browser to make requests to a protected site while authenticated as you.   Important details     Don’t disable exceptions: Be very careful if changing with: :exception: there are many ways to introduce a vulnerability if you do anything other than throw an exception when the authentity_token does not validate. https://nvisium.com/blog/2014/09/10/understanding-protectfromforgery/   Idempotent HTTP GET: You must remember to make all GET actions idempotent (does not change the data). This is because the Rails anti-CSRF only applies to HTTP POST.   Images are not protected: Images and other assets are not protected by the Rails anti-CSRF or the same-origin policy. If you have images with sensitive information, then you need an additional system to prevent a third party site from stealing these images.   If the application has a XSS vulnerability, then CSRF is also defeated.   See also     http://guides.rubyonrails.org/v4.2/security.html#csrf-countermeasures   https://www.owasp.org/index.php/Cross-Site_Request_Forgery_(CSRF)   Cookies and sessions  Authentication always triggers a session reset  You must always call reset_session immediately before setting the user id in the session. For example:  class SessionController &lt;&lt; ApplicationController   def create     user = User.authenticate(params[:username], params[:password])     if user       reset_session       session[:user_id] = user.id       redirect_to users_path(user)     else       ...     end   end end   What this does     By resetting the session before setting critical information in the session, you protect against session fixation attacks.   Why this is important     There are many ways that an attacker can “pre-seed” a session cookie in the target’s browser. Once this is done, browsers follow a simple rule with cookies: if they have a cookie that matches the site, they send the cookie. Because of this, the website has no way to distinguish between legitimate session cookies that are created by the target and nefarious session cookies created by the attacker (and injected into the target’s browser).   Important details     Encrypted and signed session cookies offer no defense against session fixation.   Even if you are using a third party authentication framework, you may still need to worry about calling reset_session yourself. This is true when the framework does not manage the session for you, but just handles the authentication (for example, omniauth).   See also     http://guides.rubyonrails.org/v4.2/security.html#session-fixation   If used, CookieStore is used carefully  By default, Rails applications will use ActionDispatch::Session::CookieStore for sessions. CookieStore is fast, but there are several pitfalls to be aware of when using CookieStore.  Do not store anything in the session…:     That is large: Cookies have a strict limit of 4k.   That you don’t want the user to see: Cookies are not encrypted, they are merely authenticated with a SHA1 digest.   That can be replayed: The user can always restore an older version of the cookie, so you can’t trust any state information stored in the user’s session.   Don’t change the default config/secrets.yml:      production:       secret_key_base: &lt;%= ENV[\"SECRET_KEY_BASE\"] %&gt;   This requires a valid session secret be created in the environment. Don’t modify this to fall back to a default value if the environment variable is not set.  Because CookieStore is easy to mess up or mis-configure, many people prefer using a traditional database-backed session storage instead.  Assets  All stylesheets have absolute paths  All stylesheets have absolute paths (to prevent CSS-injection via “Relative Path Overwrite”)  What this does     To be written   Why this is important     To be written   HTTP Headers  The gem secureheaders is enabled  The gem secureheaders allows you to conveniently configure many of best practices for HTTP headers and cookie flags.  In the apps Gemfile:  gem 'secureheaders'   In config/initializers/secure_headers.rb:  SecureHeaders::Configuration.default   What this does     Enabling this gem will give you the following default headers:   Content-Security-Policy: default-src 'self' https:; font-src 'self' https: data:; img-src 'self' https: data:; object-src 'none'; script-src https:; style-src 'self' https: 'unsafe-inline' Strict-Transport-Security: max-age=631138519 X-Content-Type-Options: nosniff X-Download-Options: noopen X-Frame-Options: sameorigin X-Permitted-Cross-Domain-Policies: none X-Xss-Protection: 1; mode=block      And cookies:    Set-Cookie: ....; Secure; HttpOnly; SameSite=Lax      Why this is important     By default, web browsers are very lax and forgiving, which is what creates a wide variety of opportunities for attack. The default headers set by secureheaders are best practices that instruct the browser to behave more strictly, and to permit many fewer avenues of attack. These options might not work with your application out of the box, but you should modify your application, if possible, to allow your site to work with these headers enabled.   Important details     secureheaders does nothing to prevent sensitive information from being cached by the web browser. For this, you must set Cache-Control header to no-store. See below.   See also     For more configuration options, see https://github.com/twitter/secureheaders/   https://www.owasp.org/index.php/Content_Security_Policy_Cheat_Sheet   TODO     Decide on CSP recommendation, given the vulnerabilities in almost all CSPs that don’t use a separate domain for assets.   Explore a more strict recommendation than the secureheaders default.   Sensitive content is not cached  If your application has sensitive content, you should instruct the browser to not cache the pages at all:  class ApplicationController &lt; ActionController::Base   before_filter :no_cache_header   protected   def no_cache_header     response.headers[\"Cache-Control\"] = \"max-age=0, private, no-store\"   end end   The important element here is no-store. The Rails default of no-cache does not prevent the browser from caching the result. It just prevents the browser from using it’s cached copy without first requesting the headers to see if the content has changed.  What is the attack here? Without no-store set, anyone who walks up to the browser and opens the cache will get the full content of all pages that a user has recently visited. Only the no-store option for Cache-Control will prevent the page contents from being saved and accessible via the browser’s cache.  To view the cache, open these in the browser’s location bar:     Chrome: chrome://cache   Firefox: about:cache   Also, you should make sure that cookies and localstorage are cleared when the user logs out.  Why this is important     Web browsers store on disk and in memory a lot of information about your site, information that is potentially very sensitive. If there is a concern that an attacker might gain physical access to a computer, then it is best to make sure your site does not have it’s pages and localstorage saved.   Databases  All queries use parameter binding  For example, this:  User.where(:name =&gt; params[:name])   But NOT this:  User.where(\"name = '#{params[:name]}'\")   Some ActiveRecord methods do not use parameter binding, even though it looks like they should. For example, these are vulnerable to SQL injection:  User.calculate(:sum, params[:column]) User.exist?(params[:id])   The exist? method in ActiveRecord only performs sanitization on string arguments. But an attacker can easy craft a request that results in params[:id] being an array. For example:  User.exist?([\"id = 1) AND 0; --\"])   Will result in the following SQL:  SELECT 1 AS one FROM \"users\" WHERE (id = 1) AND 0; --) LIMIT 1   Why it is important     Parameters queries, or stored procedures with binding, are the only way to prevent SQL injection. Please do not attempt to write your own sanitization routines: it is very difficult to account for all the weird ways in which nefarious strings can get passed your filters.   TODO     There does not appear to be a proper way to do parameter binding when making SQL calls using the database connection object directly (e.g. User.connection.select_values). Recommendation? Use sequel gem?   Views  All output is filtered  Remember, all user input should be treated as untrusted and potentially hostile. This is true even if you have attempted to filter this input and only store “safe” values in the database.  By default, Rails will filter all strings that are rendered to the page:  &lt;%= possibly_user_input %&gt;   However, Rails also lets you easily bypass the filtering. All these will create the possibility of a XSS vulnerability:  &lt;%= raw possibly_user_input %&gt; &lt;%= possibly_user_input.html_safe %&gt; &lt;%= content_tag possibly_user_input %&gt; &lt;%= link_to \"Website\", possibly_user_input %&gt;   The methods raw and html_safe should used with extreme caution, and only on strings that have no user supplied input.  Routing and URLs  There is no sensitive information in any application URLs  For example, the application should never have ?session_id=e1e6a6acadc40d2 in the URL, even for requests which redirect and do not load any page content.  Why this is important     Browsers send the HTTP referrer to whatever links a user clicks on, potentially leaking the sensitive URL. Even if that is not a possibility, the browser will still send the referrer for other requests triggered by the page, such as images an stylesheets.    There are several attacks that can take advantage of this fact to exfiltrate any sensitive information in the URL. For example, “Relative Path Overwrite”.    You can still include sensitive information in the request parameters, but these values must not appear in the URL part of the request.   Authorization  The default is to require authorization  There are two approaches to authorization:     The good way: require authorization by default, and then explicitly skip it when not needed.   The bad way: have no default authorization, and only require it when needed.   The good way:  class ApplicationController &lt; ActionController::Base   before_action :require_authorization    protected    def require_authorization     ...   end end  class HomeController &lt; ApplicationController   skip_before_action :require_authorization, only: :index   ... end   The bad way:  class ApplicationController &lt; ActionController::Base   protected   def require_authorization     ...   end end  class InventoryController &lt; ApplicationController   before_action :require_authorization   ... end   Why this is important     For something critical like authorization, you want to practice defensive programming. If there is an error in how authorization is defined for an action, it is much better to fall back to a safe default, or a hard fail, rather than to fall back to a state that leaves your application open to attack.   Pipeline  See [[ruby-tools]] for running dependency check and static analysis in your CI pipeline.  Links     http://guides.rubyonrails.org/v4.2/security.html   https://www.owasp.org/index.php/Ruby_on_Rails_Cheatsheet   https://thoughtworks.jiveon.com/docs/DOC-43719   https://rorsecurity.info/   HTML5 Security Cheatsheet https://html5sec.org/"
},{
  "title": "Rails 5 Checklist",
  "url": "/webappsec/checklists/ruby-checklists/rails-5.html",
  "tags": "",
  "content": "To be written"
},{
  "title": "Remote Logging",
  "url": "/netsec/best-practices/remote-logging.html",
  "tags": "",
  "content": "Make sure that the team’s systems are logging to Sumo Logic.  step one: identify the key strategic systems that should be logging remotely. step two: work with infosec to get these logging to sumo logic."
},{
  "title": "Dependency check for Ruby",
  "url": "/webappsec/tools/ruby-tools/ruby-dependency-checker.html",
  "tags": "",
  "content": "bundler-audit  The bundler-audit command will examine your Gemfile.lock to check for vulnerable versions of gems.  Installation  $ gem install bundler-audit   Usage  $ bundle-audit update $ bundle-audit check   For use in a pipeline, you can combine update and check together like so: $ bundle-audit check --verbose --update. The --verbose option will print out additional information about the identified vulnerability.  Run in your pipeline  Ideally, dependency checkers should be integrated into your CI pipeline. Think of this as a test (a security test) that will run as your others do and fail if either:     You have vulnerable dependencies   Updating your vulnerable dependencies causes another issue   This will, of course, depend on your configuration and what works best for your team.  For example, in .gitlab-ci.yml:  stages:   - build   - checks   - test   - deploy  bundle_audit:   stage: checks   script: |     gem install bundler-audit     bundle-audit check --update ...   Run in pre-commit  If your team uses a pre-commit script, you could run a bundler-audit check as part of that script.  Keep in mind that, if you will be using the update option, it’s probably a good idea to:     run your tests   run bundle-audit --update   run your tests again so that you can definitively tell if the update is what broke your tests."
},{
  "title": "SAML with Ruby",
  "url": "/webappsec/tutorials/ruby-saml.html",
  "tags": "",
  "content": "Terminology     Identity Provider (IdP): The SAML identity provider. In our case, this will be Okta.   Service Provider (SP): The application you are creating.   Metadata URL: A URL that specifies the location of a metadata.xml file that defines how your application is configured for use with a particular IdP. Typically, your application will check this URL each time it is started and download the contents of the file.   Create an app in Okta  Create a developer account  Add an application  The SSO endpoint for this application is:     development: http://localhost:3000/saml/acs   production: https://DOMAIN/saml/acs   In Okta, this URL would be specified for both Single Sign on URL and Audience URI.  Once the identity provider is configured, copy the IdP metadata URL.  Basic service provider  Set environment variable  Then, set the environment variable IPD_METADATA_URL before the application is run. For example:  In config/development.sh:  export IDP_METADATA_URL=\"https://dev-770989.oktapreview.com/app/exk9dbq3zdHbEBp2e0h7/sso/saml/metadata\"   Then, to run your application:  source config/development.sh rails server   In production, you would set the environment viariable via a deployment pipeline.  Gemfile  In Gemfile  gem 'ruby-saml', '~&gt; 1.4'   Routes  in config/routes.rb:  Rails.application.routes.draw do   get 'saml/login', to: 'saml#login', as: 'login'   post 'saml/acs',  to: 'saml#acs' end   SAML Controller  in app/controllers/saml_controller.rb:  # # A SAML service provider controller #  class SamlController &lt; ApplicationController   skip_before_action :verify_authenticity_token, :only =&gt; [:acs]   skip_before_action :require_authentication   skip_before_action :require_authorization    #   # GET /saml/login   #   # SP initiated login action. Redirects to IdP.   #   def login     request = OneLogin::RubySaml::Authrequest.new     redirect_to(request.create(saml_settings))   end    #   # POST /saml/acs   #   # Assertion Consumer Service URL. The endpoint that the IdP posts to.   #   def acs     response = OneLogin::RubySaml::Response.new(params[:SAMLResponse], :settings =&gt; saml_settings)     reset_session     session[:user_id] = response.nameid     redirect_to start_url   end    #   # POST /saml/logout   #   def logout     reset_session     redirect_to root_url   end    private    def saml_settings     @settings ||= begin       if ENV['IDP_METADATA_URL'] &amp;&amp; ENV['IDP_METADATA_URL'].present?         OneLogin::RubySaml::IdpMetadataParser.new.parse_remote(ENV['IDP_METADATA_URL'])       else         raise StandardError, \"The environment variable IDP_METADATA_URL is not set.\"       end     end   end  end   This controller assumes you have routes for start_url and root_url. This also assumes you have a require_authentication and require_authorization before action callbacks defined. Change these as appropriate.  Login link  Put this in a view somewhere:  &lt;%= link_to \"Log in\", login_path, class: 'login-btn' %&gt;   Add support for groups  Lets suppose you want to give access to your application to these three groups that are defined in Okta:     app_developers, with Okta group ID 0000aaaa   app_admins with Okta group ID 1111bbbb   app_readers with Okta group ID 2222cccc   The actual group IDs in Okta look more like 00g1erqthk0Why5qd0h8, but for the purpose of this tutorial we have simplified the IDs.  Add groups attribute to Okta  The first step is to modify the application configuration in Okta to add a SAML property:     Name: groups   Value: getFilteredGroups({\"0000aaaa\",\"1111bbbb\", \"2222cccc\"}, \"{group.id,group.name}\", 10)   Configure environment  Lets suppose you want to add two simple roles to your application:     Administration role: These users can edit everything.   Read only role: These users can read but not edit.   For this, create the following environment variables:  ADMIN_GROUPS – A list of SAML group IDs for users who should have full admin access to the web application.  READONLY_GROUPS – A list of SAML group IDs for users who should have READ ONLY access to the web application.  For example, in config/development.sh:  export ADMIN_GROUPS=\"0000aaaa 1111bbbb\" export READONLY_GROUPS=\"2222cccc\"   In this examples, app_developers and app_admins both gain the admin role, and app_readers gain the readonly role.  Modify SAML controller  First, add a call to resolve_group_role. This will store the role and the group name in the session when the user authenticates.    #   # A SAML service provider controller   #    class SamlController &lt; ApplicationController      def acs       response = OneLogin::RubySaml::Response.new(params[:SAMLResponse], :settings =&gt; saml_settings)       reset_session       session[:user_id] = response.nameid +     session[:role], session[:group] = resolve_group_role(response)       redirect_to start_url     end   Now lets define resolve_group_role:    class SamlError &lt; StandardError; end   rescue_from SamlError, :with =&gt; :error    private    def error(exception)     render status: 500, text: exception.to_s   end    def resolve_group_role(response)     group_str = response.attributes[\"groups\"]     if group_str.nil?       raise SamlError, \"The SAML response must include the `groups` attribute. See README.md\"     end     groups = parse_user_groups(group_str)     if group = find_group(groups, ENV['ADMIN_GROUPS'])       return [:admin, group]     elsif group = find_group(groups, ENV['READONLY_GROUPS'])       return [:reader, group]     else       raise SamlError, \"You do not belong to any groups with access to this application. Your groups are #{groups.inspect}.\"     end   end    #   # parses the list of groups that a user is a member of, as reported by saml assertion.   #   # configured in okta:   #   #   groups =&gt; getFilteredGroups({\"00gcyt4a07m0hu0pe0h7\",\"00gcyt4j78O335Ntv0h7\"}, \"{group.id, group.name}\", 10)   #   # example response.attributes[\"groups\"]:   #   #   \"00gcyt4a07m0hu0pe0h7,inventory_read,00gcyt4j78O335Ntv0h7,inventory_write\"   #   # NOTE: this will fail horribly if there is a comma in the group name.   #   def parse_user_groups(group_str)     groups = {}     ids_and_names = group_str.split(',')     while ids_and_names.any?       id = ids_and_names.shift.strip       name = ids_and_names.shift.strip       groups[id] = name     end     return groups   rescue     raise SamlError, \"ERROR: failed to parse `group` attrbute string from SAML. The string was: #{group_str.inspect}\"   end    #   # returns a group, in the form {id: group.id, name: group.name}, of the first group   # we can find that is in both user_groups and target_groups   #   # user_groups: a hash of group names, indexed by group id   # target_groups: a string of group ids, separated by commas or whitespace   #   def find_group(user_groups, target_groups)     if target_groups       target_groups.split(/[\\s,]+/).each do |group_id|         if user_groups[group_id]           return {id: group_id, name: user_groups[group_id]}         end       end     end     return nil   end  end   How would you use this? Here is a very barebones authorization code you might use:  class ApplicationController &lt; ActionController::Base   NotAuthorized = Class.new(StandardError)    before_action :require_authentication   before_action :require_authorization    rescue_from ApplicationController::NotAuthorized, :with =&gt; :render_unauthorized    protected    def render_unauthorized     render :file =&gt; Rails.root.join('public', '422.html'), :status =&gt; 403   end    def current_user     if Rails.env != \"production\" &amp;&amp; ENV[\"AUTHENTICATION_BYPASS\"]       session[:role] = \"admin\"       ENV[\"AUTHENTICATION_BYPASS\"]     else       session[:user_id]     end   end   helper_method :current_user    def require_authentication     unless current_user       redirect_to login_url     end   end    def require_authorization     if is_admin?       return true     elsif is_reader? &amp;&amp; read_only_request?       return true     else       raise NotAuthorized     end   end    def is_admin?     session[:role] == \"admin\"   end   helper_method :is_admin?    def is_reader?     session[:role] == \"reader\"   end   helper_method :is_reader? end"
},{
  "title": "Secrets management for Ruby",
  "url": "/webappsec/tools/ruby-tools/ruby-secrets-management.html",
  "tags": "",
  "content": "To be written"
},{
  "title": "Static analysis for Ruby",
  "url": "/webappsec/tools/ruby-tools/ruby-static-analysis.html",
  "tags": "",
  "content": "Brakeman  Brakeman is a great and free static analysis tool for Rails. It does not catch all vulnerabilities, but it contains a wealth of knowledge regarding best practices.  One great aspect of brakeman is that, not only does it scan your code and alert you to potential security bugs, but it also provides extensive documentation to help you understand the dangers of each vulnerability.  Installation  $ gem install brakeman   Usage  $ brakeman my-project/   You can specify the Rails version with -4 or -5.  My personal favorite way to run Brakeman if I’ve got time:  $ brakeman my-project/ -A -f html -o brakeman-report-DATE.html   My personal favorite way to run Brakeman if I’ve already run a few scans:  $ brakeman my-project/ --faster -confidence-level 2 -f html -o brakeman-report-DATE.html   Checkout further documentation on Brakeman options here.  Run in your pipeline  For example, in .gitlab-ci.yml:  stages:   - build   - checks   - test   - deploy  brakeman:   stage: checks   script: |     gem install brakeman     brakeman ...   Dawnscanner  Dawnscanner is a source code security analysis tool that is compatible with Rails, Sinatra, and Padrino.  Installation  $ gem install dawnscanner  Alternately, you can verify the gem’s signature. To be sure the gem you install hasn’t been tampered with, first add paolo@dawnscanner.org public signing certificate as trusted to your gem specific keyring.  $ gem cert --add &lt;(curl -Ls https://raw.githubusercontent.com/thesp0nge/dawnscanner/master/certs/paolo_at_dawnscanner_dot_org.pem) $ gem install dawnscanner -P MediumSecurity   Rubocop  Rubocop is source code analysis tool, primarily designed to “lint” your code. It is not specifically meant for finding security bugs, but can be configured to be useful for this purpose.  One benefit of Rubocop is that it can act as your linter as well as provide some light security analysis. If you are using a framework like Rails or Sinatra, Brakeman or Dawnscanner (respectively) are probably better bets for security-specific analysis.  That being said, Rubocop is highly configurable, and has extensive documentation. You can pick and choose which rules (aka cops) to use, and you can even write your own.  Installation  $ gem install rubocop   For more details, see the rubucop documentation).  Usage  Analyzing your files with Rubocop is as simple as running  $ cd my_project $ rubocop   Of course, there are some fancier options as well. Some particularly interesting ones for security purposes are:  --except  Allows you to exclude particular cops or departments (the general category that cops reside in, i.e. Department = Layout, cops = SpaceBeforeComma, TrailingWhitespace, etc.)  --only  The opposite of the except option  -D/--display-cop-names  This will include the cop names in the output so you can see which cops are particularly useful and/or noisy. This might help you figure out which to use with --except and --only.  Of course, you can find all of the other available options in the usual ways.  Configuration  You can customize the config file, and even specify mulitple config files at runtime.  You can also specify inherit_from in your .rubocop.yml config file. You can inherit from other files in your project, as well as a remote URL."
},{
  "title": "Second Factor Authentication",
  "url": "/opsec/level-three/second-factor-authentication.html",
  "tags": "",
  "content": "* [Security Self-defense / How to: Enable Two Factor Authentication](https://ssd.eff.org/en/module/how-enable-two-factor-authentication) * [Security Planner / Second Factor](https://securityplanner.org/#/tool/2-factor-authentication) * [Security Planner / Security Key](https://securityplanner.org/#/tool/security-key)"
},{
  "title": "Secrets Management",
  "url": "/webappsec/best-practices/secrets-management.html",
  "tags": "",
  "content": "### What is it?  Secrets such as passwords, credentials, access tokens, certificates, and other confidential information are something we can't allow to fall into the wrong hands. A secret management tool makes it possible to manage these kinds of secrets safely.  ### Why is it needed?  We see this more than you'd think. The dangers of leaving secrets into your code are wide ranging and severe. It could lead to everything from an attacker compromising a user's session to full owning your application, and even the application server, gaining access to your database, and impersonating you to uncover more valuable data (and this is not an exhaustive list).  * Applications rely on secrets to access services such as databases, encrypted files, and to securely communicate with other applications and systems. * Team members may also need a way to manage and share similar confidential information. * Writing secrets in a place they can be easily retrieved exposes projects to unnecessary risks. This includes doing things like writing them on sticky notes or in source code or configuration files.  ### Tools  * [[agnostic-secrets-management]]"
},{
  "title": "Security Advisories",
  "url": "/netsec/best-practices/security-advisories.html",
  "tags": "",
  "content": "### Step 1 - Create a Patch Management List  First, create a list of all the major software that your systems rely on but that are not checked automatically using a dependency checker in a test pipeline. For example, you do not need to add libraries that a web application depends on to your patch management list, but you should add the operating system, the web server, the database server, and so on.  ### Step 2 - Identify notification sources  For every item in your list, write down the URL for where you can find canonical vulnerability information. All major software projects will offer this. Often, you can also subscribe to a mailing list.  Alternately, there are commercial services that will handle this patch management notification for you.  ### Step 3 - Set the date  Pick a day on the calender where you will check every URL on your list to see if there are any new vulnerabilities listed since the last time you checked."
},{
  "title": "Software Best Practices",
  "url": "/opsec/level-one/software.html",
  "tags": "",
  "content": "# Keep your software up to date  Nearly every time an attacker is able to compromise a computer through a software vulnerability the attack could have been prevented if the software was up to date. This is because almost all vulnerabilities are known to the software developers and have already been fixed by the time attackers learn to take advantage of the flaws.  It is especially important to keep your operating system up to date, since the operating system has privileged access to everything that happens on your device.  How to turn on automatic updates:  * **macOS**: Select the **Apple** menu, then select **System Preferences** > **App Store** > **Automatically check for updates**. * **Windows**: Select the **Start** button, then select **Settings** > **Update & security** > **Windows Update** > **Advanced options** and then under **Choose how updates are installed**, select **Automatic (recommended)**.  Caveats:  * You may need to restart your device for many updates to take effect, so allowing your device to restart after an update is required for the update to provide protection. * If you have specific software requirements or custom software created for your organization, automatic updates can cause work disruption, as some OS updates may be incompatible with existing software. * Keeping your software up to date does not help with Phishing or Malware attacks, which work by tricking the user into performing unsafe behavior.  # Use the application store  When possible, it is best to install software from the official application store for your operating system, for several reasons:  * **Authenticity**: Applications in the application store are signed by the developer and verified by the application store. * **Updates**: The application store will help you keep your applications up to date. * **Prevent Side Loading Attacks**: Installing an application outside the official application store is called \"side loading\". Side loading is currently disabled by default on Android, impossible on iOS, and is enabled by default on macOS and Windows. When side loading is enabled, your computer is more vulnerable to many different forms of malware attacks. For this reason, both macOS and Windows are trying to move to a model where side loading is disabled by default.  Note: You need to use caution with the official Android application store, Google Play, as there are often copycat applications designed to impersonate the real application.  # When in doubt, don't install  The proliferation of mobile apps, browser extensions and other free (as in zero-cost, not open source) programs has caused numerous security problems. Avoid software that hasn't been created by a company you already have a trust relationship with (i.e., any company whose tools you are already using at your organization).  Software that appears to have good intentions (like antivirus scanning) or beneficial features may be masking malicious activities in the background. In most browsers and mobile devices, an application will ask for certain permissions at installation--the information and hardware it can access on your device. These are worth looking at to make sure they at least vaguely reflect what is expected. For example, if a flashlight app asks for permissions to your contacts or to make phone calls, you probably don't want to install it. Permissions to be especially cautious around granting include access to your calls, contacts, camera, microphone, location services, or entire storage.  The way to look at permissions after installation depends on the context. In Chrome, go to chrome://extensions/ and click the permissions link for each one. On iOS devices, under Settings is a list of all permissions; under each permission is the list of apps that use it. On Android devices, go to Settings > Application Manager to view a list of apps; under each app is the list of permissions it uses.  Unfortunately most software installation systems on laptops and desktop computers will not ask for permission to access resources, so you should be extra careful about installation of software not from a mobile, browser or OS app store.  # Do not use pirated software  Install pirated software is a great way to infect your computer with a virus or other malware.  Additionally, if you install pirated software on your work computer, it is very likely that your company will have to pay thousands of dollars in fines for your single device. When this happens, you might be fired for violating the security and privacy policies of your employer.  If there is an application you must have, and you don't want to obtain it through secure channels, consider using one of the free and open source software alternatives.  # Use free software  These free and open source applications are great alternatives to commonly used commercial products, available for Mac, Windows, and Linux:  [Gimp](https://www.gimp.org/) : Raster graphics and photo editing program (alternative to Adobe Photoshop)  [Inkscape](https://inkscape.org/en/) : Vector drawing program (alternative to Adobe Illustrator)  [LibreOffice](https://www.libreoffice.org/) : Office productivity suite (alternative to Microsoft Office)  [Scribus](https://www.scribus.net) : Desktop publishing application (alternative to Adobe InDesign)  # See also  * [Security Planner / Update Your Windows Computer](https://securityplanner.org/#/tool/update-your-windows-computer) * [Security Planner / Keep Your Mac Updated](https://securityplanner.org/#/tool/keep-your-mac-updated) * [Security Planner / Use Safe Apps](https://securityplanner.org/#/tool/use-safe-apps)"
},{
  "title": "Static analysis",
  "url": "/webappsec/best-practices/static-analysis.html",
  "tags": "",
  "content": "### What is it?  A static analysis tool, referred to as a Static Application Security Tool (SAST) in the context of security, identifies potential security flaws in source code, byte code, and binaries. SAST tools provide a powerful way to identify potential defects by analyzing applications from the \"inside out\". This provides much greater sight into possible flaws than a scanner that only interacts with a application as a user would.  ### Why is it needed?  * Sometimes the easiest or most obvious way to do something is also not secure.   These tools provide fast feedback if a mistake is made. * Continuous, fast feedback about potential vulnerabilities saves teams time and   stress.  ### When should I use this?  * In your CI pipeline. Automatically run the scanner periodically, possibly   alongside other automated tests following a checkin if it can complete quickly   enough. * During manual testing. More in-depth scans can be run and verified along with   the other necessary manual tests. Testers can also start to do some   exploratory security testing after familiarizing themselves with typical   weaknesses.  ### Tools  * [[agnostic-static-analysis]] * [[java-static-analysis]] * [[javascript-static-analysis]] * [[python-static-analysis]] * [[ruby-static-analysis]]  ### Further reading  * [Wikipedia page on static program analysis](https://en.wikipedia.org/wiki/Static_program_analysis) * [Wikipedia list of static program analyzers](https://en.wikipedia.org/wiki/List_of_tools_for_static_code_analysis) * [OWASP wiki page on static program analysis](https://www.owasp.org/index.php/Static_Code_Analysis) * [NIST list of security-focused static program analyzers](https://samate.nist.gov/index.php/Source_Code_Security_Analyzers.html)"
},{
  "title": "System Administrators",
  "url": "/netsec/best-practices/system-administrators.html",
  "tags": "",
  "content": "Create a list of responsible sysadmins. These are the folks we need to engage with directly. (sysadmin here would mean anyone with access to an VPC control panel or with SSH access to the server).  Review offboarding procedures for sysadmins with privileged access."
},{
  "title": "Systems Inventory",
  "url": "/netsec/best-practices/systems-inventory.html",
  "tags": "",
  "content": "Create a list of systems, physical and virtual, owned by the team. IP Address, Hostname, OS, and Role. Ensure that this system inventory is scanned by Tenable Security Center, or otherwise input into the inventory tracker, and that the team is assigned ownership of these assets."
},{
  "title": "Threat Modeling",
  "url": "/netsec/threat-modeling.html",
  "tags": "",
  "content": "https://www.owasp.org/index.php/Threat_Risk_Modeling  https://www.schneier.com/academic/archives/1999/12/attack_trees.html  https://msdn.microsoft.com/en-us/library/ff648644.aspx    Step 1. Identify Assets   Step 2. Create an Architecture Overview   Step 3. Decompose the Application   Step 4. Identify the Threats   Step 5. Document the Threats   Step 6. Rate the Threats  ## Work and data flows  * identify what assets the team owns * identify what data is in them * map the flow of data * classify the data * mitigate the highest risk first"
},{
  "title": "Network Security Tools",
  "url": "/netsec/tools.html",
  "tags": "",
  "content": "## CyberChef  Swiss Army Knife for encoded information: does conversions, decryption, hashing, everything. Very handy!  https://gchq.github.io/CyberChef  ## Snoopy Logger  https://github.com/a2o/snoopy logs all shell commands to syslog not useful for forensics, because it can be bypassed, but useful to audit what has happened manually and if an attacker doesn't know its there.  ## VULNREPORT  http://vulnreport.io/  automation and management platform for penetration tests and security audits"
},{
  "title": "Tor",
  "url": "/opsec/level-three/tor.html",
  "tags": "",
  "content": "# See also  * [Security Self-defense / How to: Use Tor for Linux](https://ssd.eff.org/en/module/how-use-tor-linux) * [Security Self-defense / How to: Use Tor for Windows](https://ssd.eff.org/en/module/how-use-tor-windows) * [Security Self-defense / How to: Use Tor for macOS](https://ssd.eff.org/en/module/how-use-tor-macos) * [Security Planner / Orbot and Orfox](https://securityplanner.org/#/tool/orbot-and-orfox) * [Security Planner / Tor Browser](https://securityplanner.org/#/tool/tor-browser) * [Security Planner / Onion Browser](https://securityplanner.org/#/tool/onion-browser)"
},{
  "title": "VPN",
  "url": "/opsec/level-two/vpn.html",
  "tags": "",
  "content": "# See Also  * [Security Planner / Virtual Private Network](https://securityplanner.org/#/tool/virtual-private-network) * [Security In-a-box / Remain Anonymous and Bypass Censorship on the Internet](https://securityinabox.org/en/guide/anonymity-and-circumvention/) * [Security Self-defense / How to: Circumvent Online Censorship](https://ssd.eff.org/en/module/how-circumvent-online-censorship) * [Security Self-defense / Choosing the VPN That's Right for You](https://ssd.eff.org/en/module/choosing-vpn-thats-right-you)"
},{
  "title": "Vulnerability Scanning",
  "url": "/netsec/best-practices/vulnerability-scanning.html",
  "tags": "",
  "content": "Make sure that the team's systems are being scanned. Review the scan results and remediate all vulnerabilities.  Ensure that all the assets are being scanned, set up VPC peering connections as needed. Check the latest scan, and ensure that there are no items that need to be addressed"
},{}
]
